#!/usr/bin/env python3
"""
Test corrigÃ© de l'API Responses de GPT-5
BasÃ© sur les erreurs dÃ©couvertes lors des premiers tests
"""

import os
import sys
import json
from datetime import datetime
from openai import OpenAI

def check_environment():
    """VÃ©rifie la configuration de l'environnement"""
    print("ğŸ” VÃ‰RIFICATION DE L'ENVIRONNEMENT")
    print("=" * 50)
    
    # VÃ©rifier OpenAI API Key
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEY non configurÃ©e")
        print("ğŸ’¡ Pour configurer :")
        print("   1. CrÃ©ez un fichier .env avec OPENAI_API_KEY=votre_clÃ©")
        print("   2. Ou exportez la variable : set OPENAI_API_KEY=votre_clÃ©")
        return False
    
    print(f"âœ… OPENAI_API_KEY configurÃ©e: {openai_key[:10]}...")
    
    # VÃ©rifier la version d'OpenAI
    try:
        import openai
        print(f"âœ… Version OpenAI: {openai.__version__}")
    except Exception as e:
        print(f"âš ï¸ Impossible de vÃ©rifier la version OpenAI: {e}")
    
    return True

def test_basic_responses(client):
    """Test de base sans paramÃ¨tres include"""
    print("\nğŸ¯ TEST 1: RÃ‰PONSE DE BASE (SANS INCLUDE)")
    print("-" * 50)
    
    try:
        response = client.responses.create(
            model="gpt-5",
            instructions="Tu es un analyste financier. Analyse briÃ¨vement le marchÃ© actuel en 2-3 phrases. Commence par 'ANALYSE:'",
            input="Quelle est la situation actuelle du marchÃ© boursier ?",
            max_output_tokens=150
        )
        
        print(f"âœ… SuccÃ¨s - Status: {getattr(response, 'status', 'N/A')}")
        print(f"ğŸ“ Output text: '{getattr(response, 'output_text', 'N/A')}'")
        
        # Afficher les mÃ©tadonnÃ©es
        print(f"\nğŸ“Š MÃ‰TADONNÃ‰ES:")
        print(f"  - Request ID: {getattr(response, '_request_id', 'N/A')}")
        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            print(f"  - Input tokens: {getattr(usage, 'input_tokens', 'N/A')}")
            print(f"  - Output tokens: {getattr(usage, 'output_tokens', 'N/A')}")
            print(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
        
        # Explorer la structure de la rÃ©ponse
        print(f"\nğŸ” STRUCTURE DE LA RÃ‰PONSE:")
        print(f"  - Tous les attributs: {[attr for attr in dir(response) if not attr.startswith('_')]}")
        
        if hasattr(response, 'output') and response.output:
            print(f"\nğŸ“¦ OUTPUT DÃ‰TAILLÃ‰:")
            for i, item in enumerate(response.output):
                print(f"  Item {i}:")
                print(f"    - Type: {getattr(item, 'type', 'N/A')}")
                print(f"    - ID: {getattr(item, 'id', 'N/A')}")
                print(f"    - Summary: {getattr(item, 'summary', 'N/A')}")
                print(f"    - Content: {getattr(item, 'content', 'N/A')}")
                print(f"    - Status: {getattr(item, 'status', 'N/A')}")
                print(f"    - Tous les attributs: {[attr for attr in dir(item) if not attr.startswith('_')]}")
        
        return response
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None

def test_with_reasoning_object(client):
    """Test avec le paramÃ¨tre reasoning comme objet (pas boolÃ©en)"""
    print("\nğŸ§  TEST 2: AVEC RAISONNEMENT (REASONING OBJECT)")
    print("-" * 50)
    
    try:
        response = client.responses.create(
            model="gpt-5",
            instructions="Tu es un analyste financier. Analyse le marchÃ© en dÃ©tail. Commence par 'ANALYSE:'",
            input="Quelle est la situation actuelle du marchÃ© boursier ?",
            max_output_tokens=200,
            reasoning={"type": "auto"}  # Objet au lieu de boolÃ©en
        )
        
        print(f"âœ… SuccÃ¨s - Status: {getattr(response, 'status', 'N/A')}")
        print(f"ğŸ“ Output text: '{getattr(response, 'output_text', 'N/A')}'")
        
        # VÃ©rifier le raisonnement
        if hasattr(response, 'reasoning') and response.reasoning:
            print(f"\nğŸ§  RAISONNEMENT:")
            # VÃ©rifier si c'est un objet avec une mÃ©thode len ou un attribut
            if hasattr(response.reasoning, '__len__'):
                print(f"  - Nombre d'items: {len(response.reasoning)}")
                for i, item in enumerate(response.reasoning):
                    print(f"    Item {i}:")
                    print(f"      - Type: {getattr(item, 'type', 'N/A')}")
                    print(f"      - Status: {getattr(item, 'status', 'N/A')}")
                    if hasattr(item, 'content') and item.content:
                        print(f"      - Content: {len(item.content)} Ã©lÃ©ments")
            else:
                print(f"  - Raisonnement: {response.reasoning}")
                print(f"  - Type: {type(response.reasoning)}")
                print(f"  - Attributs: {[attr for attr in dir(response.reasoning) if not attr.startswith('_')]}")
        
        return response
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None

def test_with_include_parameters_corrected(client):
    """Test avec les paramÃ¨tres include corrigÃ©s"""
    print("\nğŸ”§ TEST 3: PARAMÃˆTRES INCLUDE CORRIGÃ‰S")
    print("-" * 50)
    
    # Liste des paramÃ¨tres include Ã  tester (corrigÃ©s)
    include_options = [
        ["reasoning.encrypted_content"],
        ["reasoning.encrypted_content", "code_interpreter_call.outputs"],
        ["file_search_call.results"]
    ]
    
    for i, include_list in enumerate(include_options):
        print(f"\nğŸ“‹ Test {i+1}: {include_list}")
        print("-" * 30)
        
        try:
            response = client.responses.create(
                model="gpt-5",
                instructions="Tu es un analyste financier. Donne une analyse concise. Commence par 'ANALYSE:'",
                input="Quelle est la situation actuelle du marchÃ© boursier ?",
                max_output_tokens=150,
                include=include_list
            )
            
            print(f"âœ… SuccÃ¨s - Status: {getattr(response, 'status', 'N/A')}")
            print(f"ğŸ“ Output text: '{getattr(response, 'output_text', 'N/A')}'")
            
            # VÃ©rifier les Ã©lÃ©ments inclus
            if "reasoning.encrypted_content" in include_list:
                if hasattr(response, 'reasoning') and response.reasoning:
                    print(f"  ğŸ§  Reasoning disponible")
                    # VÃ©rifier la structure du raisonnement
                    if hasattr(response.reasoning, '__len__'):
                        print(f"    - Nombre d'items: {len(response.reasoning)}")
                    else:
                        print(f"    - Type: {type(response.reasoning)}")
            
            if "code_interpreter_call.outputs" in include_list:
                print(f"  ğŸ”§ Code interpreter outputs demandÃ©s")
            
            if "file_search_call.results" in include_list:
                print(f"  ğŸ“ File search results demandÃ©s")
            
        except Exception as e:
            print(f"âŒ Erreur: {e}")

def test_streaming_responses_corrected(client):
    """Test du streaming avec l'API Responses (corrigÃ©)"""
    print("\nğŸŒŠ TEST 4: STREAMING RESPONSES (CORRIGÃ‰)")
    print("-" * 50)
    
    try:
        with client.responses.stream(
            model="gpt-5",
            instructions="Tu es un analyste financier. Donne une analyse en temps rÃ©el. Commence par 'ANALYSE:'",
            input="Quelle est la situation actuelle du marchÃ© boursier ?",
            max_output_tokens=200
        ) as stream:
            
            print("ğŸ”„ Streaming en cours...")
            buffer = []
            
            for event in stream:
                print(f"ğŸ“¡ Event: {event.type}")
                if event.type == "response.output_text.delta":
                    delta = getattr(event, 'delta', '')
                    buffer.append(delta)
                    print(f"ğŸ“ Delta: '{delta}'")
                elif event.type == "response.completed":
                    print("âœ… Streaming terminÃ©")
                    break
            
            final_text = "".join(buffer).strip()
            print(f"\nğŸ“‹ Texte final: '{final_text}'")
            
    except Exception as e:
        print(f"âŒ Erreur streaming: {e}")

def test_extract_text_utility_corrected():
    """Test de la fonction utilitaire d'extraction de texte (corrigÃ©e)"""
    print("\nğŸ› ï¸ TEST 5: FONCTION UTILITAIRE EXTRACT_TEXT (CORRIGÃ‰E)")
    print("-" * 50)
    
    # Simuler une rÃ©ponse pour tester la fonction
    class MockResponse:
        def __init__(self, output_text=None, output=None, usage=None):
            self.output_text = output_text
            self.output = output
            self.usage = usage
            self._request_id = "test_123"
    
    def extract_text(res) -> str:
        """Fonction utilitaire d'extraction de texte (corrigÃ©e)"""
        try:
            # 1) Voie rapide - output_text direct
            if getattr(res, "output_text", None):
                t = (res.output_text or "").strip()
                if t:
                    return t
            
            # 2) Parcourir la structure "output" (avec vÃ©rification None)
            chunks = []
            output = getattr(res, "output", None)
            if output and hasattr(output, '__iter__'):
                for item in output:
                    # Messages assistant
                    if getattr(item, "role", "") == "assistant":
                        content = getattr(item, "content", None)
                        if content and hasattr(content, '__iter__'):
                            for part in content:
                                if getattr(part, "type", "") == "output_text" and getattr(part, "text", None):
                                    chunks.append(part.text)
            
            if chunks:
                return "\n".join(chunks).strip()
            
            return ""
            
        except Exception as e:
            print(f"âŒ Erreur dans extract_text: {e}")
            return ""
    
    # Test avec output_text
    mock_res1 = MockResponse(output_text="Test de rÃ©ponse")
    result1 = extract_text(mock_res1)
    print(f"âœ… Test output_text: '{result1}'")
    
    # Test avec output structurÃ©
    mock_res2 = MockResponse(
        output=[
            type('MockItem', (), {
                'role': 'assistant',
                'content': [
                    type('MockPart', (), {
                        'type': 'output_text',
                        'text': 'RÃ©ponse structurÃ©e'
                    })()
                ]
            })()
        ]
    )
    result2 = extract_text(mock_res2)
    print(f"âœ… Test output structurÃ©: '{result2}'")
    
    # Test avec rÃ©ponse vide
    mock_res3 = MockResponse()
    result3 = extract_text(mock_res3)
    print(f"âœ… Test rÃ©ponse vide: '{result3}'")

def test_prompt_optimization():
    """Test de l'optimisation des prompts"""
    print("\nğŸ¯ TEST 6: OPTIMISATION DES PROMPTS")
    print("-" * 50)
    
    base_prompt = "Tu es un analyste financier. Analyse le marchÃ©."
    
    # Test avec force_output=True
    optimized_prompt = f"""{base_prompt}

IMPORTANT: Tu DOIS Ã©mettre une rÃ©ponse finale en texte.
- Commence ta rÃ©ponse par "OK â€“"
- Sois concis et direct
- Ã‰vite de rester dans le raisonnement interne
"""
    
    print(f"ğŸ“ Prompt de base: {base_prompt}")
    print(f"ğŸ“ Prompt optimisÃ©: {optimized_prompt}")
    print("âœ… Prompt optimisÃ© crÃ©Ã© avec succÃ¨s")

def main():
    """Fonction principale de test"""
    print("ğŸš€ TEST CORRIGÃ‰ DE L'API RESPONSES GPT-5")
    print("=" * 60)
    print(f"â° DÃ©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # VÃ©rifier l'environnement
    if not check_environment():
        return
    
    # Initialiser le client OpenAI
    try:
        client = OpenAI()
        print("âœ… Client OpenAI initialisÃ©")
    except Exception as e:
        print(f"âŒ Erreur initialisation client OpenAI: {e}")
        return
    
    # Tests
    test_basic_responses(client)
    test_with_reasoning_object(client)
    test_with_include_parameters_corrected(client)
    test_streaming_responses_corrected(client)
    test_extract_text_utility_corrected()
    test_prompt_optimization()
    
    print(f"\nğŸ‰ TESTS TERMINÃ‰S - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nğŸ“‹ RÃ‰SUMÃ‰ DES DÃ‰COUVERTES:")
    print("  âœ… L'API Responses fonctionne mais output_text est vide")
    print("  âœ… Le paramÃ¨tre reasoning doit Ãªtre un objet, pas un boolÃ©en")
    print("  âœ… Les logprobs ne sont pas supportÃ©s avec les modÃ¨les de raisonnement")
    print("  âœ… Le streaming fonctionne mais sans le paramÃ¨tre text.type")
    print("  âœ… La structure de rÃ©ponse est complexe et nÃ©cessite une extraction robuste")

if __name__ == "__main__":
    main()
