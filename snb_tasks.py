"""
T√¢ches Celery pour le module SNB
Permet l'ex√©cution en background du scraping
"""

import os
import sys
import subprocess
from celery_app import celery


@celery.task(bind=True, name='snb_tasks.snb_collect_task')
def snb_collect_task(self, mode: str = 'monthly'):
    """
    T√¢che Celery pour la collecte SNB (background worker)
    
    Args:
        mode: 'daily', 'monthly', 'quarterly', ou 'all'
    
    Returns:
        dict avec success, message, output
    """
    try:
        self.update_state(state='PROGRESS', meta={'step': 'starting', 'mode': mode, 'pct': 10})
        
        # Lancer le scraper en subprocess
        cmd = [sys.executable, "snb_auto_scraper.py", f"--{mode}"]
        
        self.update_state(state='PROGRESS', meta={'step': 'scraping', 'mode': mode, 'pct': 30})
        
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # Attendre max 180 secondes (3 minutes pour scraping complexe)
        try:
            stdout, stderr = process.communicate(timeout=180)
            
            self.update_state(state='PROGRESS', meta={'step': 'completed', 'pct': 100})
            
            if process.returncode == 0:
                return {
                    "success": True,
                    "message": f"Collecte {mode} terminee avec succes",
                    "output": stdout,
                    "errors": stderr if stderr else None
                }
            else:
                return {
                    "success": False,
                    "error": f"Scraper failed with code {process.returncode}",
                    "output": stdout,
                    "stderr": stderr
                }
                
        except subprocess.TimeoutExpired:
            process.kill()
            self.update_state(state='FAILURE', meta={'error': 'Timeout'})
            return {
                "success": False,
                "error": "Timeout: La collecte a pris plus de 180 secondes"
            }
    
    except Exception as e:
        import traceback
        self.update_state(state='FAILURE', meta={'error': str(e)})
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@celery.task(bind=True, name='snb_tasks.snb_neer_collect_task')
def snb_neer_collect_task(self):
    """
    T√¢che Celery pour collecter le NEER depuis data.snb.ch
    
    Returns:
        dict avec success, neer_change_3m_pct
    """
    try:
        from snb_neer_collector import collect_neer_from_snb_api
        
        self.update_state(state='PROGRESS', meta={'step': 'fetching_neer', 'pct': 50})
        
        result = collect_neer_from_snb_api()
        
        self.update_state(state='PROGRESS', meta={'step': 'completed', 'pct': 100})
        
        return {
            "success": True,
            "neer_change_3m_pct": result.get("neer_change_3m_pct"),
            "neer_value": result.get("neer_value")
        }
    
    except Exception as e:
        import traceback
        self.update_state(state='FAILURE', meta={'error': str(e)})
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@celery.task(bind=True, name='snb_tasks.snb_explain_task')
def snb_explain_task(self, model_run_id: int = None, model_json: dict = None, tone: str = 'concise', lang: str = 'fr-CH'):
    """
    T√¢che Celery pour g√©n√©rer l'explication GPT-5 en background
    √âvite le timeout Gunicorn worker (GPT-5 reasoning_effort=high prend 7-10s)
    
    Args:
        model_json: JSON du mod√®le BNS
        tone: Ton de l'explication
        lang: Langue (fr-CH par d√©faut)
    
    Returns:
        dict avec success, explanation (JSON)
    """
    try:
        import os
        import json
        from openai import OpenAI
        
        self.update_state(state='PROGRESS', meta={'step': 'calling_gpt5', 'pct': 30})
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return {
                "success": False,
                "error": "OpenAI API key not configured"
            }
        
        client = OpenAI(api_key=api_key)
        
        # Si model_run_id fourni, r√©cup√©rer depuis Supabase (plus simple √† s√©rialiser)
        if model_run_id and not model_json:
            from flask import current_app
            supabase = current_app.config.get('SUPABASE_CLIENT')
            if supabase:
                result = supabase.table("snb_model_runs").select("*").eq("id", model_run_id).execute()
                if result.data:
                    run = result.data[0]
                    model_json = {
                        "as_of": run["as_of"],
                        "inputs": json.loads(run["inputs"]) if isinstance(run["inputs"], str) else run["inputs"],
                        "nowcast": json.loads(run["nowcast"]) if isinstance(run["nowcast"], str) else run["nowcast"],
                        "output_gap_pct": run["output_gap_pct"],
                        "i_star_next_pct": run["i_star_next_pct"],
                        "probs": json.loads(run["probs"]) if isinstance(run["probs"], str) else run["probs"],
                        "path": json.loads(run["path"]) if isinstance(run["path"], str) else run["path"],
                        "version": run["version"]
                    }
        
        if not model_json:
            return {"success": False, "error": "No model data provided"}
        
        # Prompt syst√®me optimis√© pour lisibilit√© et d√©tails
        system_prompt = f"""Tu es un strat√©giste senior de banque centrale sp√©cialis√© dans la politique mon√©taire suisse (Banque Nationale Suisse - BNS).

Tu dois analyser les r√©sultats du mod√®le quantitatif de pr√©vision des taux et fournir une explication D√âTAILL√âE, P√âDAGOGIQUE et ACCESSIBLE en {lang}.

R√àGLES IMP√âRATIVES D'√âCRITURE:
1. AUCUN ACRONYME sans l'√©crire en toutes lettres la premi√®re fois (ex: "Indice des Prix √† la Consommation (CPI)" pas juste "CPI")
2. PHRASES COMPL√àTES et explicatives (pas de style t√©l√©graphique)
3. CONTEXTE ET EXPLICATIONS pour chaque chiffre (pourquoi c'est important?)
4. COMPARAISONS avec les cibles BNS (inflation cible 1%, output gap neutre 0%)
5. INTERPR√âTATIONS claires des probabilit√©s (ex: "85% de maintien signifie quasi-certitude")
6. VOCABULAIRE ACCESSIBLE (√©viter jargon technique sauf si explicit√©)

STRUCTURE OBLIGATOIRE (JSON strict):
{{
  "headline": "Titre principal clair et compr√©hensible de 60-90 caract√®res",
  "bullets": [
    "Point 1: Analyse d√©taill√©e de l'inflation actuelle (valeur, √©cart vs cible 1%, tendance). √âcrire les acronymes en entier.",
    "Point 2: Situation de l'√©conomie suisse (output gap, barom√®tre KOF, que signifient ces indicateurs concr√®tement?)",
    "Point 3: Ce que le mod√®le √©conomique recommande (r√®gle de Taylor) et pourquoi",
    "Point 4: Ce que les march√©s financiers anticipent (Futures SARON, taux OIS) et leur interpr√©tation",
    "Point 5: Quelle est la pr√©vision finale combin√©e (fusion Kalman) et niveau de confiance",
    "Point 6: Contexte international (franc suisse, commerce, politiques autres banques centrales)",
    "Point 7 (optionnel): Facteurs additionnels, calendrier, √©l√©ments techniques"
  ],
  "risks": [
    "Risque majeur 1 expliqu√© clairement (pas juste 'CHF fort' mais 'appr√©ciation du franc suisse qui...')",
    "Risque majeur 2 avec son impact potentiel",
    "Risques secondaires (2-3) avec explications"
  ],
  "next_steps": [
    "Indicateur √† surveiller 1: pourquoi c'est important et quand",
    "Indicateur √† surveiller 2: son impact sur la d√©cision BNS",
    "Action recommand√©e 3: ce qu'il faut faire concr√®tement"
  ],
  "one_liner": "Synth√®se tr√®s claire en une phrase de 120-150 caract√®res (accessible √† tous)"
}}

CONTEXTE BNS (√† utiliser):
- Cible d'inflation BNS: 1.0% (stabilit√© des prix = inflation entre 0% et 2%)
- Derni√®res d√©cisions: MPA septembre 2025, taux maintenu √† 0%
- Pr√©visions conditionnelles BNS: 2025=0.2%, 2026=0.5%, 2027=0.7%
- Output gap neutre = 0%, n√©gatif = sous-capacit√©, positif = surchauffe

STYLE D'√âCRITURE:
- Phrases fluides et naturelles (comme si tu expliquais √† un investisseur intelligent mais non-expert)
- √âviter: "CPI a/a", "i*", "pb", "bps", "YoY" ‚Üí Utiliser: "inflation annuelle", "taux optimal", "pour cent", "variation sur un an"
- Chaque chiffre doit √™tre CONTEXTUALIS√â (ex: pas "0.2%" mais "0.2%, soit largement sous la cible de 1%")
- Minimum 50-70 mots par bullet point (soyez exhaustif et p√©dagogique)

FORMAT:
- JSON STRICT, pas de texte avant/apr√®s
- UTF-8, accents fran√ßais corrects
- Pas de markdown, pas de ```json```

R√âPONDS UNIQUEMENT EN JSON VALIDE.
"""
        
        user_prompt = f"Voici le JSON du mod√®le BNS √† analyser:\n\n{json.dumps(model_json, indent=2, ensure_ascii=False)}"
        
        self.update_state(state='PROGRESS', meta={'step': 'gpt5_reasoning', 'pct': 50})
        
        print("=" * 80)
        print("üì° APPEL OPENAI GPT-5 (Background Worker)")
        print(f"Model: gpt-5 | Reasoning effort: high | Max tokens: 10000")
        print(f"Tone: {tone} | Lang: {lang}")
        print(f"Note: Verbosit√© contr√¥l√©e via prompt syst√®me (d√©tails via instructions)")
        print("-" * 80)
        
        # Appel OpenAI GPT-5 Responses API
        # reasoning.effort = profondeur du raisonnement
        # text.verbosity = longueur/d√©tail de la r√©ponse
        response = client.responses.create(
            model="gpt-5",
            reasoning={
                "effort": "high"      # Raisonnement approfondi (low/medium/high)
            },
            text={
                "verbosity": "high"   # Verbosit√© √©lev√©e (low/medium/high)
            },
            max_output_tokens=10000,  # Maximum de tokens en sortie
            instructions=system_prompt,
            input=user_prompt
        )
        
        response_text = response.output_text
        
        print(f"‚úÖ GPT-5 r√©ponse re√ßue")
        print(f"   Tokens: input={response.usage.input_tokens}, output={response.usage.output_tokens}, total={response.usage.total_tokens}")
        # Reasoning tokens (peut ne pas exister selon le mod√®le)
        if hasattr(response.usage, 'reasoning_tokens') and response.usage.reasoning_tokens:
            print(f"   Reasoning tokens: {response.usage.reasoning_tokens}")
        else:
            print(f"   Reasoning: Non disponible (mod√®le ne retourne pas reasoning_tokens)")
        # Debug complet de l'objet usage
        print(f"   Usage object: {response.usage}")
        print("=" * 80)
        
        self.update_state(state='PROGRESS', meta={'step': 'parsing_json', 'pct': 90})
        
        # Parse JSON
        try:
            explanation = json.loads(response_text)
        except json.JSONDecodeError:
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                explanation = json.loads(json_match.group(0))
            else:
                raise ValueError("GPT response is not valid JSON")
        
        # Validation
        required_keys = ["headline", "bullets", "risks", "next_steps", "one_liner"]
        for key in required_keys:
            if key not in explanation:
                explanation[key] = f"[{key} manquant]"
        
        self.update_state(state='PROGRESS', meta={'step': 'completed', 'pct': 100})
        
        return {
            "success": True,
            "explanation": explanation,
            "tokens": {
                "input": int(response.usage.input_tokens) if response.usage.input_tokens else 0,
                "output": int(response.usage.output_tokens) if response.usage.output_tokens else 0,
                "total": int(response.usage.total_tokens) if response.usage.total_tokens else 0,
                "reasoning": int(getattr(response.usage, 'reasoning_tokens', 0) or 0)
            }
        }
    
    except Exception as e:
        import traceback
        self.update_state(state='FAILURE', meta={'error': str(e)})
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }

