#!/usr/bin/env python3
"""
Gestionnaire de base de donn√©es pour les analyses de march√© du Background Worker
"""

import os
import json
import logging
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from supabase import create_client, Client

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def _coerce_float(value: Any) -> Optional[float]:
    """Convertit en float ou retourne None si impossible (g√®re 'N/A', '', None)."""
    if value is None:
        return None
    if isinstance(value, (int, float)):
        return float(value)
    try:
        s = str(value).strip()
        if s.lower() in {"n/a", "na", "nan", "", "none"}:
            return None
        return float(s)
    except Exception:
        return None

@dataclass
class MarketAnalysis:
    """Mod√®le de donn√©es pour une analyse de march√©"""
    id: Optional[int] = None
    timestamp: Optional[str] = None
    analysis_type: str = 'automatic'
    prompt: Optional[str] = None
    executive_summary: Optional[List[str]] = None
    summary: Optional[str] = None
    key_points: Optional[List[str]] = None
    structured_data: Optional[Dict[str, Any]] = None
    geopolitical_analysis: Optional[Dict[str, Any]] = None
    economic_indicators: Optional[Dict[str, Any]] = None
    insights: Optional[List[str]] = None
    risks: Optional[List[str]] = None
    opportunities: Optional[List[str]] = None
    sources: Optional[List[Dict[str, str]]] = None
    confidence_score: Optional[float] = None
    worker_status: str = 'completed'
    processing_time_seconds: Optional[int] = None
    error_message: Optional[str] = None
    created_at: Optional[str] = None
    updated_at: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour Supabase"""
        data = asdict(self)
        # Convertir les listes en JSONB pour Supabase
        if self.executive_summary:
            data['executive_summary'] = json.dumps(self.executive_summary)
        if self.key_points:
            data['key_points'] = json.dumps(self.key_points)
        if self.insights:
            data['insights'] = json.dumps(self.insights)
        if self.risks:
            data['risks'] = json.dumps(self.risks)
        if self.opportunities:
            data['opportunities'] = json.dumps(self.opportunities)
        if self.sources:
            data['sources'] = json.dumps(self.sources)
        if self.structured_data:
            data['structured_data'] = json.dumps(self.structured_data)
        if self.geopolitical_analysis:
            data['geopolitical_analysis'] = json.dumps(self.geopolitical_analysis)
        if self.economic_indicators:
            data['economic_indicators'] = json.dumps(self.economic_indicators)
        
        # Assainir les champs num√©riques susceptibles d'√™tre 'N/A'
        if 'confidence_score' in data:
            coerced = _coerce_float(data.get('confidence_score'))
            if coerced is None:
                data.pop('confidence_score', None)
            else:
                data['confidence_score'] = coerced
        if 'processing_time_seconds' in data and data.get('processing_time_seconds') is not None:
            try:
                data['processing_time_seconds'] = int(data['processing_time_seconds'])
            except Exception:
                data.pop('processing_time_seconds', None)

        # Supprimer les champs None
        return {k: v for k, v in data.items() if v is not None}

    def to_frontend_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour le frontend (JSON valide)."""
        data = asdict(self)
        # Assurer que les champs JSON sont des listes/dict et non des strings
        json_fields = ['executive_summary', 'key_points', 'insights', 'risks', 'opportunities', 'sources', 'structured_data', 'geopolitical_analysis', 'economic_indicators']
        dict_fields = {'structured_data', 'geopolitical_analysis', 'economic_indicators'}
        for field in json_fields:
            if isinstance(data.get(field), str):
                try:
                    data[field] = json.loads(data[field])
                except (json.JSONDecodeError, TypeError):
                    logger.warning(f"Impossible de d√©coder le JSON pour le champ {field}")
                    # Remplacer par une valeur par d√©faut en cas d'erreur
                    if field in dict_fields:
                        data[field] = {}
                    elif field == 'sources':
                        data[field] = []
                    else:
                        data[field] = []
        
        return {k: v for k, v in data.items() if v is not None}


    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MarketAnalysis':
        """Cr√©e une instance depuis un dictionnaire de Supabase"""
        # Convertir les JSONB en listes/dictionnaires de mani√®re robuste
        def _safe_json_load(value: Any, default: Any):
            if isinstance(value, (list, dict)):
                return value
            if isinstance(value, str):
                s = value.strip()
                if not s:
                    return default
                try:
                    return json.loads(s)
                except Exception:
                    logger.warning("JSON invalide d√©tect√©, utilisation d'une valeur par d√©faut")
                    return default
            return default

        data['executive_summary'] = _safe_json_load(data.get('executive_summary'), [])
        data['key_points'] = _safe_json_load(data.get('key_points'), [])
        data['insights'] = _safe_json_load(data.get('insights'), [])
        data['risks'] = _safe_json_load(data.get('risks'), [])
        data['opportunities'] = _safe_json_load(data.get('opportunities'), [])
        data['sources'] = _safe_json_load(data.get('sources'), [])
        data['structured_data'] = _safe_json_load(data.get('structured_data'), {})
        data['geopolitical_analysis'] = _safe_json_load(data.get('geopolitical_analysis'), {})
        data['economic_indicators'] = _safe_json_load(data.get('economic_indicators'), {})
        
        return cls(**data)

class MarketAnalysisDB:
    """Gestionnaire de base de donn√©es pour les analyses de march√©"""
    
    def __init__(self):
        """Initialise la connexion √† Supabase"""
        try:
            supabase_url = os.getenv('SUPABASE_URL')
            supabase_key = os.getenv('SUPABASE_KEY')
            
            if not supabase_url or not supabase_key:
                raise ValueError("Variables d'environnement Supabase manquantes")
            
            self.supabase: Client = create_client(supabase_url, supabase_key)
            logger.info("‚úÖ Connexion √† Supabase √©tablie pour Market Analysis DB")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur connexion Supabase: {e}")
            self.supabase = None
    
    def is_connected(self) -> bool:
        """V√©rifie si la connexion est √©tablie"""
        return self.supabase is not None
    
    def save_analysis(self, analysis: MarketAnalysis) -> Optional[int]:
        """Sauvegarde une analyse de march√©"""
        try:
            if not self.is_connected():
                logger.error("‚ùå Pas de connexion √† Supabase")
                return None
            
            # Pr√©parer les donn√©es
            data = analysis.to_dict()
            if not analysis.timestamp:
                data['timestamp'] = datetime.now(timezone.utc).isoformat()
            
            # Ins√©rer dans la base de donn√©es
            result = self.supabase.table('market_analyses').insert(data).execute()
            
            if result.data:
                analysis_id = result.data[0]['id']
                logger.info(f"‚úÖ Analyse sauvegard√©e avec l'ID: {analysis_id}")
                return analysis_id
            else:
                logger.error("‚ùå Erreur lors de la sauvegarde de l'analyse")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde analyse: {e}")
            return None
    
    def get_latest_analysis(self) -> Optional[MarketAnalysis]:
        """R√©cup√®re la derni√®re analyse de march√©"""
        try:
            if not self.is_connected():
                logger.error("‚ùå Pas de connexion √† Supabase")
                return None
            
            result = self.supabase.table('market_analyses')\
                .select('*')\
                .order('timestamp', desc=True)\
                .limit(1)\
                .execute()
            
            if result.data:
                analysis_data = result.data[0]
                analysis = MarketAnalysis.from_dict(analysis_data)
                logger.info(f"‚úÖ Derni√®re analyse r√©cup√©r√©e (ID: {analysis.id})")
                return analysis
            else:
                logger.info("‚ÑπÔ∏è Aucune analyse trouv√©e dans la base de donn√©es")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration derni√®re analyse: {e}")
            return None
    
    def get_analyses_by_type(self, analysis_type: str, limit: int = 10) -> List[MarketAnalysis]:
        """R√©cup√®re les analyses par type"""
        try:
            if not self.is_connected():
                logger.error("‚ùå Pas de connexion √† Supabase")
                return []
            
            result = self.supabase.table('market_analyses')\
                .select('*')\
                .eq('analysis_type', analysis_type)\
                .order('timestamp', desc=True)\
                .limit(limit)\
                .execute()
            
            analyses = []
            for data in result.data:
                analysis = MarketAnalysis.from_dict(data)
                analyses.append(analysis)
            
            logger.info(f"‚úÖ {len(analyses)} analyses de type '{analysis_type}' r√©cup√©r√©es")
            return analyses
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration analyses par type: {e}")
            return []

    def get_recent_analyses(self, limit: int = 15) -> List[MarketAnalysis]:
        """Retourne les derni√®res analyses (tous types), tri√©es par created_at d√©croissant."""
        try:
            if not self.is_connected():
                logger.error("‚ùå Pas de connexion √† Supabase")
                return []

            # Pr√©f√©rer l'ordre par timestamp si pr√©sent; fallback created_at sinon
            try:
                result = self.supabase.table('market_analyses') \
                    .select('*') \
                    .order('timestamp', desc=True) \
                    .limit(limit) \
                    .execute()
            except Exception:
                result = self.supabase.table('market_analyses') \
                    .select('*') \
                    .order('created_at', desc=True) \
                    .limit(limit) \
                    .execute()

            analyses: List[MarketAnalysis] = []
            for data in result.data or []:
                try:
                    analyses.append(MarketAnalysis.from_dict(data))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Analyse ignor√©e (deserialization): {e}")

            logger.info(f"‚úÖ {len(analyses)} analyses r√©centes r√©cup√©r√©es")
            return analyses
        except Exception as e:
            logger.error(f"‚ùå Erreur get_recent_analyses: {e}")
            return []

    def get_pending_analysis(self) -> Optional[MarketAnalysis]:
        """R√©cup√®re la plus ancienne analyse en attente."""
        try:
            if not self.is_connected(): return None
            
            result = self.supabase.table('market_analyses')\
                .select('*')\
                .eq('worker_status', 'pending')\
                .order('created_at', desc=False)\
                .limit(1)\
                .execute()
                
            if result.data:
                analysis = MarketAnalysis.from_dict(result.data[0])
                logger.info(f"‚ÑπÔ∏è T√¢che en attente trouv√©e: ID {analysis.id}")
                return analysis
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur get_pending_analysis: {e}")
            return None

    def update_analysis_status(self, analysis_id: int, status: str):
        """Met √† jour uniquement le statut d'une analyse."""
        self.update_analysis(analysis_id, {'worker_status': status})

    def update_analysis(self, analysis_id: int, data: Dict[str, Any]) -> bool:
        """Met √† jour une analyse avec de nouvelles donn√©es."""
        try:
            if not self.is_connected(): return False
            
            # Assurer la mise √† jour de 'updated_at'
            data['updated_at'] = datetime.now(timezone.utc).isoformat()

            # Assainir les champs num√©riques (√©viter 22P02 sur 'N/A')
            if 'confidence_score' in data:
                coerced = _coerce_float(data.get('confidence_score'))
                if coerced is None:
                    data.pop('confidence_score', None)
                else:
                    data['confidence_score'] = coerced
            if 'processing_time_seconds' in data:
                try:
                    data['processing_time_seconds'] = int(data['processing_time_seconds'])
                except Exception:
                    data.pop('processing_time_seconds', None)

            # Uniformiser les champs JSON (√©viter le stockage de repr Python non valide)
            try:
                json_list_fields = ['executive_summary', 'key_points', 'insights', 'risks', 'opportunities', 'sources']
                json_dict_fields = ['structured_data', 'geopolitical_analysis', 'economic_indicators']
                for field in json_list_fields:
                    if field in data:
                        val = data[field]
                        if isinstance(val, (list, dict)):
                            # Forcer un JSON string valide
                            data[field] = json.dumps(val, ensure_ascii=False)
                        elif isinstance(val, str):
                            s = val.strip()
                            if not s:
                                data[field] = json.dumps([], ensure_ascii=False)
                            else:
                                # Tenter de valider; si invalide, fallback en liste vide
                                try:
                                    parsed = json.loads(s)
                                    if not isinstance(parsed, list):
                                        parsed = []
                                    data[field] = json.dumps(parsed, ensure_ascii=False)
                                except Exception:
                                    data[field] = json.dumps([], ensure_ascii=False)
                        else:
                            data[field] = json.dumps([], ensure_ascii=False)

                for field in json_dict_fields:
                    if field in data:
                        val = data[field]
                        if isinstance(val, dict):
                            data[field] = json.dumps(val, ensure_ascii=False)
                        elif isinstance(val, str):
                            s = val.strip()
                            if not s:
                                data[field] = json.dumps({}, ensure_ascii=False)
                            else:
                                try:
                                    parsed = json.loads(s)
                                    if not isinstance(parsed, dict):
                                        parsed = {}
                                    data[field] = json.dumps(parsed, ensure_ascii=False)
                                except Exception:
                                    data[field] = json.dumps({}, ensure_ascii=False)
                        else:
                            data[field] = json.dumps({}, ensure_ascii=False)
            except Exception as _e:
                logger.warning(f"‚ö†Ô∏è Normalisation des champs JSON √©chou√©e (fallbacks appliqu√©s): {_e}")
            
            # Effectuer la mise √† jour; le SDK Python ne supporte pas .select() apr√®s update
            self.supabase.table('market_analyses') \
                .update(data) \
                .eq('id', analysis_id) \
                .execute()

            # Si aucune exception n'a √©t√© lev√©e, consid√©rer la mise √† jour comme r√©ussie
            logger.info(f"‚úÖ Analyse ID {analysis_id} mise √† jour.")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur update_analysis: {e}")
            return False

    def delete_analysis(self, analysis_id: int) -> bool:
        """Supprime une analyse par son ID."""
        try:
            if not self.is_connected():
                return False
            result = self.supabase.table('market_analyses') \
                .delete() \
                .eq('id', analysis_id) \
                .execute()

            if result.data is not None:
                logger.info(f"üóëÔ∏è Analyse ID {analysis_id} supprim√©e")
                return True
            logger.error(f"‚ùå √âchec suppression analyse ID {analysis_id}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur delete_analysis: {e}")
            return False

    def get_analysis_by_id(self, analysis_id: int) -> Optional[MarketAnalysis]:
        """R√©cup√®re une analyse sp√©cifique par son ID."""
        try:
            if not self.is_connected():
                logger.error("‚ùå Pas de connexion √† Supabase")
                return None
            
            result = self.supabase.table('market_analyses')\
                .select('*')\
                .eq('id', analysis_id)\
                .execute()
            
            if result.data:
                analysis_data = result.data[0]
                analysis = MarketAnalysis.from_dict(analysis_data)
                logger.info(f"‚úÖ Analyse #{analysis_id} r√©cup√©r√©e")
                return analysis
            else:
                logger.warning(f"‚ö†Ô∏è Aucune analyse trouv√©e avec l'ID {analysis_id}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration analyse #{analysis_id}: {e}")
            return None

    
    def get_worker_status(self) -> Dict[str, Any]:
        """R√©cup√®re le statut du Background Worker"""
        try:
            if not self.is_connected():
                return {"available": False, "error": "Pas de connexion √† Supabase"}
            
            # V√©rifier la derni√®re analyse
            latest = self.get_latest_analysis()
            if not latest:
                return {
                    "available": True,
                    "status": "no_analysis",
                    "message": "Aucune analyse disponible",
                    "last_check": datetime.now(timezone.utc).isoformat()
                }
            
            # V√©rifier si l'analyse est r√©cente (moins de 6 heures)
            if latest.timestamp:
                analysis_time = datetime.fromisoformat(latest.timestamp.replace('Z', '+00:00'))
                now = datetime.now(timezone.utc)
                hours_since_analysis = (now - analysis_time).total_seconds() / 3600
                
                if hours_since_analysis < 6:
                    return {
                        "available": True,
                        "status": "recent_analysis",
                        "last_analysis": latest.timestamp,
                        "hours_since_analysis": round(hours_since_analysis, 1),
                        "last_check": now.isoformat()
                    }
                else:
                    return {
                        "available": True,
                        "status": "stale_analysis",
                        "last_analysis": latest.timestamp,
                        "hours_since_analysis": round(hours_since_analysis, 1),
                        "message": "Derni√®re analyse ancienne",
                        "last_check": now.isoformat()
                    }
            
            return {
                "available": True,
                "status": "unknown",
                "last_check": datetime.now(timezone.utc).isoformat()
            }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification statut worker: {e}")
            return {"available": False, "error": str(e)}
    
    def create_test_analysis(self) -> Optional[int]:
        """Cr√©e une analyse de test pour v√©rifier la base de donn√©es"""
        try:
            test_analysis = MarketAnalysis(
                analysis_type='test',
                summary='Analyse de test g√©n√©r√©e automatiquement',
                key_points=[
                    'Test de la base de donn√©es',
                    'V√©rification de la connexion',
                    'Test des fonctionnalit√©s'
                ],
                structured_data={
                    'prix': 'Test',
                    'tendance': 'Test',
                    'volumes': 'Test'
                },
                insights=['Test de la base de donn√©es'],
                risks=['Aucun risque'],
                opportunities=['Test r√©ussi'],
                sources=[{'title': 'Test Analysis', 'url': '#'}],
                confidence_score=0.95,
                worker_status='completed'
            )
            
            return self.save_analysis(test_analysis)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation analyse de test: {e}")
            return None

# Instance globale
market_analysis_db = MarketAnalysisDB()

def get_market_analysis_db() -> MarketAnalysisDB:
    """Retourne l'instance globale du gestionnaire de base de donn√©es"""
    return market_analysis_db 