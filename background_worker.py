#!/usr/bin/env python3
"""
Background Worker pour Render - Traite les analyses de march√© en file d'attente
"""

import os
import asyncio
import time
import logging
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Imports
from scrapingbee_scraper import get_scrapingbee_scraper
from market_analysis_db import get_market_analysis_db, MarketAnalysis

class MarketAnalysisWorker:
    def __init__(self):
        self.scraper = get_scrapingbee_scraper()
        self.db = get_market_analysis_db()
        self.poll_interval_seconds = 15  # V√©rifier les nouvelles t√¢ches toutes les 15 secondes
        self.is_running = False

    def initialize(self):
        """Initialise le worker et ses d√©pendances."""
        try:
            logger.info("üöÄ Initialisation du Background Worker...")
            # V√©rification des variables d'environnement
            required = ['SCRAPINGBEE_API_KEY', 'OPENAI_API_KEY', 'SUPABASE_URL', 'SUPABASE_KEY']
            if any(not os.getenv(var) for var in required):
                raise ValueError(f"Variables d'environnement manquantes: {', '.join(v for v in required if not os.getenv(v))}")

            self.scraper.initialize_sync()
            if not self.db.is_connected():
                raise ConnectionError("Connexion √† la base de donn√©es impossible.")
            
            self.is_running = True
            logger.info(f"‚úÖ Worker pr√™t. Intervalle de v√©rification: {self.poll_interval_seconds}s")
        except Exception as e:
            logger.error(f"‚ùå Erreur d'initialisation fatale: {e}")
            raise

    async def process_task(self, task: MarketAnalysis):
        """Traite une seule t√¢che d'analyse."""
        start_time = time.time()
        task_id = task.id
        logger.info(f"üìä Prise en charge de la t√¢che #{task_id}...")

        try:
            # 1. Mettre √† jour le statut √† "processing"
            self.db.update_analysis_status(task_id, 'processing')

            # 2. Ex√©cuter le scraping et l'analyse LLM
            prompt = task.prompt or "Analyse g√©n√©rale des march√©s financiers avec focus sur l'IA."
            
            scraper_task_id = await self.scraper.create_scraping_task(prompt, 3)
            result = await self.scraper.execute_scraping_task(scraper_task_id)

            # 3. Traiter le r√©sultat
            if "error" in result:
                raise ValueError(result['error'])

            processing_time = int(time.time() - start_time)
            
            # 4. Mettre √† jour la t√¢che avec les r√©sultats complets
            update_data = {
                'summary': result.get('summary'),
                'key_points': result.get('key_points', []),
                'structured_data': result.get('structured_data', {}),
                'insights': result.get('insights', []),
                'risks': result.get('risks', []),
                'opportunities': result.get('opportunities', []),
                'sources': result.get('sources', []),
                'confidence_score': result.get('confidence_score', 0.0),
                'worker_status': 'completed',
                'processing_time_seconds': processing_time
            }
            self.db.update_analysis(task_id, update_data)
            logger.info(f"‚úÖ T√¢che #{task_id} termin√©e avec succ√®s en {processing_time}s.")

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du traitement de la t√¢che #{task_id}: {e}")
            processing_time = int(time.time() - start_time)
            self.db.update_analysis(task_id, {
                'worker_status': 'error',
                'error_message': str(e),
                'processing_time_seconds': processing_time
            })

    async def run_continuous_loop(self):
        """Boucle principale qui recherche et traite les t√¢ches."""
        logger.info("üîÑ D√©marrage de la boucle de traitement des t√¢ches...")
        while self.is_running:
            try:
                # Chercher une t√¢che en attente
                pending_task = self.db.get_pending_analysis()

                if pending_task:
                    await self.process_task(pending_task)
                else:
                    # Pas de t√¢che, on attend avant de v√©rifier √† nouveau
                    await asyncio.sleep(self.poll_interval_seconds)

            except Exception as e:
                logger.error(f"‚ùå Erreur dans la boucle principale: {e}")
                await asyncio.sleep(60) # Attendre plus longtemps en cas d'erreur grave

    def stop(self):
        """Arr√™te proprement le worker."""
        logger.info("üõë Arr√™t du Background Worker...")
        self.is_running = False
        if hasattr(self.scraper, 'cleanup'):
            self.scraper.cleanup()

async def main():
    """Point d'entr√©e principal."""
    worker = MarketAnalysisWorker()
    try:
        worker.initialize()
        await worker.run_continuous_loop()
    except (KeyboardInterrupt, SystemExit):
        logger.info("Arr√™t initi√©.")
    except Exception as e:
        logger.error(f"‚ùå Le worker s'est arr√™t√© en raison d'une erreur fatale: {e}")
    finally:
        worker.stop()

if __name__ == "__main__":
    asyncio.run(main())
