#!/usr/bin/env python3
"""
Background Worker pour Render - Traite les analyses de marchÃ© en file d'attente
"""

import os
import asyncio
import time
import logging
import json
from datetime import datetime, timezone, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import smtplib
from typing import Dict
from dotenv import load_dotenv

# Optional Redis cache
try:
    import redis  # type: ignore
except Exception:  # pragma: no cover
    redis = None

# Charger les variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

logger.info("--- DÃ‰MARRAGE DU SCRIPT DU BACKGROUND WORKER ---")

# Imports
from scrapingbee_scraper import get_scrapingbee_scraper
from market_analysis_db import get_market_analysis_db, MarketAnalysis
from stock_api_manager import stock_api_manager
 

class MarketAnalysisWorker:
    def __init__(self):
        self.scraper = get_scrapingbee_scraper()
        self.db = get_market_analysis_db()
        # NewsAPI removed; ScrapingBee is the only source for analysis
        self.poll_interval_seconds = 15  # VÃ©rifier les nouvelles tÃ¢ches toutes les 15 secondes
        self.is_running = False
        self.redis_client = None
        self._init_redis()

    def _init_redis(self) -> None:
        """Initialise Redis si disponible (facultatif)."""
        try:
            redis_url = os.getenv("REDIS_URL")
            if redis and redis_url:
                self.redis_client = redis.from_url(redis_url, decode_responses=True)
                # Ping pour valider la connexion
                self.redis_client.ping()
                logger.info("âœ… Cache Redis initialisÃ©")
            else:
                if not redis:
                    logger.info("â„¹ï¸ Redis non installÃ©, cache dÃ©sactivÃ©")
                elif not redis_url:
                    logger.info("â„¹ï¸ REDIS_URL non dÃ©fini, cache dÃ©sactivÃ©")
        except Exception as e:
            logger.warning(f"âš ï¸ Impossible d'initialiser Redis: {e}")
            self.redis_client = None

    def initialize(self):
        """Initialise le worker et ses dÃ©pendances."""
        try:
            logger.info("ğŸš€ Initialisation du Background Worker...")
            # VÃ©rification des variables d'environnement
            required = ['SCRAPINGBEE_API_KEY', 'OPENAI_API_KEY', 'SUPABASE_URL', 'SUPABASE_KEY']
            if any(not os.getenv(var) for var in required):
                raise ValueError(f"Variables d'environnement manquantes: {', '.join(v for v in required if not os.getenv(v))}")

            self.scraper.initialize_sync()
            if not self.db.is_connected():
                raise ConnectionError("Connexion Ã  la base de donnÃ©es impossible.")
            
            self.is_running = True
            logger.info(f"âœ… Worker prÃªt. Intervalle de vÃ©rification: {self.poll_interval_seconds}s")
        except Exception as e:
            logger.error(f"âŒ Erreur d'initialisation fatale: {e}")
            raise

    async def process_task(self, task: MarketAnalysis):
        """Traite une seule tÃ¢che d'analyse."""
        start_time = time.time()
        task_id = task.id
        logger.info(f"ğŸ“Š Prise en charge de la tÃ¢che #{task_id}...")
        logger.info(f"   - Type: {task.analysis_type}")
        logger.info(f"   - Prompt: {task.prompt[:100]}...")

        try:
            # 1. Mettre Ã  jour le statut Ã  "processing"
            logger.info(f"ğŸ”„ Mise Ã  jour du statut de la tÃ¢che #{task_id} Ã  'processing'...")
            self.db.update_analysis_status(task_id, 'processing')

            # 2. ExÃ©cuter l'analyse (ScrapingBee uniquement)
            prompt = task.prompt or "Analyse gÃ©nÃ©rale des marchÃ©s financiers avec focus sur l'IA."
            logger.info(f"ğŸ•·ï¸ CrÃ©ation de la tÃ¢che ScrapingBee avec prompt: {prompt[:100]}...")
            scraper_task_id = await self.scraper.create_scraping_task(prompt, 3)
            
            logger.info(f"ğŸš€ ExÃ©cution de la tÃ¢che ScrapingBee {scraper_task_id}...")
            result = await self.scraper.execute_scraping_task(scraper_task_id)


            # 3. Traiter le rÃ©sultat
            if "error" in result:
                logger.error(f"âŒ Erreur reÃ§ue de ScrapingBee: {result['error']}")
                raise ValueError(result['error'])

            processing_time = int(time.time() - start_time)
            
            logger.info(f"ğŸ“Š RÃ©sultats obtenus:")
            logger.info(f"   - Executive Summary: {len(result.get('executive_summary', []))} points")
            logger.info(f"   - RÃ©sumÃ©: {len(result.get('summary', ''))} caractÃ¨res")
            logger.info(f"   - Points clÃ©s: {len(result.get('key_points', []))} points")
            logger.info(f"   - Insights: {len(result.get('insights', []))} insights")
            logger.info(f"   - Sources: {len(result.get('sources', []))} sources")
            
            # 4. Mettre Ã  jour la tÃ¢che avec les rÃ©sultats complets
            update_data = {
                'executive_summary': result.get('executive_summary', []),
                'summary': result.get('summary'),
                'key_points': result.get('key_points', []),
                'structured_data': result.get('structured_data', {}),
                'insights': result.get('insights', []),
                'risks': result.get('risks', []),
                'opportunities': result.get('opportunities', []),
                'sources': result.get('sources', []),
                'confidence_score': result.get('confidence_score', 0.0),
                'worker_status': 'completed',
                'processing_time_seconds': processing_time
            }
            
            logger.info(f"ğŸ’¾ Sauvegarde des rÃ©sultats dans la base de donnÃ©es...")
            self.db.update_analysis(task_id, update_data)
            logger.info(f"âœ… TÃ¢che #{task_id} terminÃ©e avec succÃ¨s en {processing_time}s.")
            
            # 5. Envoyer le rapport par email (si configurÃ©)
            await self._send_market_analysis_email(task_id, result)

        except Exception as e:
            logger.error(f"âŒ Erreur lors du traitement de la tÃ¢che #{task_id}: {e}")
            processing_time = int(time.time() - start_time)
            self.db.update_analysis(task_id, {
                'worker_status': 'error',
                'error_message': str(e),
                'processing_time_seconds': processing_time
            })

    async def _send_market_analysis_email(self, task_id: int, analysis_result: Dict):
        """Envoie le rapport d'analyse de marchÃ© par email."""
        try:
            # VÃ©rifier la configuration email
            email_host = os.getenv("EMAIL_HOST", "smtp.gmail.com")
            email_port = int(os.getenv("EMAIL_PORT", "587"))
            email_user = os.getenv("EMAIL_USER")
            email_password = os.getenv("EMAIL_PASSWORD")
            recipients = [e.strip() for e in os.getenv("EMAIL_RECIPIENTS", "").split(",") if e.strip()]
            
            if not (email_user and email_password and recipients):
                logger.info("â„¹ï¸ Configuration email incomplÃ¨te, pas d'envoi")
                return
            
            # RÃ©cupÃ©rer l'analyse complÃ¨te depuis la DB
            analysis = self.db.get_analysis_by_id(task_id)
            if not analysis:
                logger.warning(f"âš ï¸ Impossible de rÃ©cupÃ©rer l'analyse #{task_id} pour l'email")
                return
            
            # PrÃ©parer le contenu HTML
            html_content = self._generate_market_analysis_html(analysis, analysis_result)
            
            # CrÃ©er et envoyer l'email
            msg = MIMEMultipart('alternative')
            msg['From'] = email_user
            msg['To'] = ", ".join(recipients)
            msg['Subject'] = f"[BONVIN] Rapport d'Analyse de MarchÃ© - {datetime.now().strftime('%d/%m/%Y %H:%M')}"
            
            msg.attach(MIMEText(html_content, 'html', 'utf-8'))
            
            with smtplib.SMTP(email_host, email_port) as server:
                server.starttls()
                server.login(email_user, email_password)
                server.send_message(msg)
            
            logger.info(f"ğŸ“§ Rapport d'analyse #{task_id} envoyÃ© par email Ã  {len(recipients)} destinataires")
            
        except Exception as e:
            logger.error(f"âŒ Erreur envoi email rapport #{task_id}: {e}")

    def _generate_market_analysis_html(self, analysis: 'MarketAnalysis', result: Dict) -> str:
        """GÃ©nÃ¨re le contenu HTML pour l'email."""
        # RÃ©cupÃ©rer les donnÃ©es du snapshot de marchÃ©
        from stock_api_manager import stock_api_manager
        market_snapshot = stock_api_manager.get_market_snapshot()
        
        # GÃ©nÃ©rer le HTML
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
                .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; border-bottom: 3px solid #1e3a8a; padding-bottom: 20px; margin-bottom: 30px; }}
                .header h1 {{ color: #1e3a8a; margin: 0; }}
                .header .date {{ color: #666; font-size: 14px; margin-top: 10px; }}
                .executive-summary {{ background: linear-gradient(135deg, #1e3a8a, #3b82f6); color: white; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}
                .executive-summary h2 {{ margin-top: 0; color: #fbbf24; }}
                .executive-summary ul {{ margin: 0; padding-left: 20px; }}
                .executive-summary li {{ margin-bottom: 8px; font-size: 16px; }}
                .section {{ margin-bottom: 30px; }}
                .section h3 {{ color: #1e3a8a; border-bottom: 2px solid #e5e7eb; padding-bottom: 10px; }}
                .market-snapshot {{ background: #f8fafc; padding: 20px; border-radius: 8px; border-left: 4px solid #3b82f6; }}
                .market-snapshot table {{ width: 100%; border-collapse: collapse; }}
                .market-snapshot th, .market-snapshot td {{ padding: 8px; text-align: left; border-bottom: 1px solid #e5e7eb; }}
                .market-snapshot th {{ background: #3b82f6; color: white; }}
                .insights {{ background: #fef3c7; padding: 20px; border-radius: 8px; border-left: 4px solid #f59e0b; }}
                .risks {{ background: #fee2e2; padding: 20px; border-radius: 8px; border-left: 4px solid #ef4444; }}
                .opportunities {{ background: #dcfce7; padding: 20px; border-radius: 8px; border-left: 4px solid #22c55e; }}
                .footer {{ text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #e5e7eb; color: #666; font-size: 12px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ“Š RAPPORT D'ANALYSE DE MARCHÃ‰</h1>
                    <div class="date">GÃ©nÃ©rÃ© le {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')}</div>
                </div>
                
                <!-- Executive Summary -->
                <div class="executive-summary">
                    <h2>ğŸ¯ EXECUTIVE SUMMARY</h2>
                    <ul>
                        {chr(10).join([f'<li>{point}</li>' for point in (result.get('executive_summary', []) or [])])}
                    </ul>
                </div>
                
                <!-- RÃ©sumÃ© dÃ©taillÃ© -->
                <div class="section">
                    <h3>ğŸ“ RÃ©sumÃ© de l'Analyse</h3>
                    <p>{result.get('summary', 'Aucun rÃ©sumÃ© disponible')}</p>
                </div>
                
                <!-- AperÃ§u du marchÃ© -->
                <div class="section">
                    <h3>ğŸ“ˆ AperÃ§u du MarchÃ©</h3>
                    <div class="market-snapshot">
                        <table>
                            <thead>
                                <tr><th>Actif</th><th>Prix</th><th>Variation</th><th>Source</th></tr>
                            </thead>
                            <tbody>
                                {self._generate_market_snapshot_rows(market_snapshot)}
                            </tbody>
                        </table>
                    </div>
                </div>
                
                <!-- Points clÃ©s -->
                <div class="section">
                    <h3>ğŸ”‘ Points ClÃ©s</h3>
                    <ul>
                        {chr(10).join([f'<li>{point}</li>' for point in (result.get('key_points', []) or [])])}
                    </ul>
                </div>
                
                <!-- Insights -->
                <div class="insights">
                    <h3>ğŸ’¡ Insights</h3>
                    <ul>
                        {chr(10).join([f'<li>{insight}</li>' for insight in (result.get('insights', []) or [])])}
                    </ul>
                </div>
                
                <!-- Risques -->
                <div class="risks">
                    <h3>âš ï¸ Risques IdentifiÃ©s</h3>
                    <ul>
                        {chr(10).join([f'<li>{risk}</li>' for insight in (result.get('risks', []) or [])])}
                    </ul>
                </div>
                
                <!-- OpportunitÃ©s -->
                <div class="opportunities">
                    <h3>ğŸš€ OpportunitÃ©s</h3>
                    <ul>
                        {chr(10).join([f'<li>{opp}</li>' for opp in (result.get('opportunities', []) or [])])}
                    </ul>
                </div>
                
                <!-- Sources -->
                <div class="section">
                    <h3>ğŸ“š Sources</h3>
                    <ul>
                        {chr(10).join([f'<li><a href="{source.get("url", "#")}" target="_blank">{source.get("title", "Source")}</a></li>' for source in (result.get('sources', []) or [])])}
                    </ul>
                </div>
                
                <div class="footer">
                    <p>Rapport gÃ©nÃ©rÃ© automatiquement par le systÃ¨me BONVIN Collection</p>
                    <p>Confiance: {result.get('confidence_score', 0) * 100:.1f}%</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html

    def _generate_market_snapshot_rows(self, snapshot: Dict) -> str:
        """GÃ©nÃ¨re les lignes du tableau de snapshot de marchÃ©."""
        rows = []
        
        if snapshot.get('indices'):
            rows.append('<tr><td colspan="4" style="background: #e5e7eb; font-weight: bold; padding: 10px;">Indices</td></tr>')
            for name, data in snapshot['indices'].items():
                change_color = 'green' if data.get('change', 0) >= 0 else 'red'
                rows.append(f'''
                    <tr>
                        <td><strong>{name}</strong></td>
                        <td>{data.get('price', 'N/A')}</td>
                        <td style="color: {change_color}">{data.get('change', 'N/A')} ({data.get('change_percent', 'N/A')}%)</td>
                        <td>yfinance</td>
                    </tr>
                ''')
        
        if snapshot.get('commodities'):
            rows.append('<tr><td colspan="4" style="background: #e5e7eb; font-weight: bold; padding: 10px;">MatiÃ¨res PremiÃ¨res</td></tr>')
            for name, data in snapshot['commodities'].items():
                change_color = 'green' if data.get('change', 0) >= 0 else 'red'
                rows.append(f'''
                    <tr>
                        <td><strong>{name}</strong></td>
                        <td>{data.get('price', 'N/A')}</td>
                        <td style="color: {change_color}">{data.get('change', 'N/A')} ({data.get('change_percent', 'N/A')}%)</td>
                        <td>yfinance</td>
                    </tr>
                ''')
        
        if snapshot.get('crypto'):
            rows.append('<tr><td colspan="4" style="background: #e5e7eb; font-weight: bold; padding: 10px;">Cryptomonnaies</td></tr>')
            for name, data in snapshot['crypto'].items():
                change_color = 'green' if data.get('change', 0) >= 0 else 'red'
                rows.append(f'''
                    <tr>
                        <td><strong>{name}</strong></td>
                        <td>{data.get('price', 'N/A')}</td>
                        <td style="color: {change_color}">{data.get('change', 'N/A')} ({data.get('change_percent', 'N/A')}%)</td>
                        <td>yfinance</td>
                    </tr>
                ''')
        
        return chr(10).join(rows) if rows else '<tr><td colspan="4">Aucune donnÃ©e disponible</td></tr>'

    # NewsAPI analysis path removed

    async def run_continuous_loop(self):
        """Boucle principale qui recherche et traite les tÃ¢ches."""
        logger.info("ğŸ”„ DÃ©marrage de la boucle de traitement des tÃ¢ches...")
        check_count = 0
        while self.is_running:
            try:
                check_count += 1
                if check_count % 20 == 1:  # Log toutes les 5 minutes environ
                    logger.info(f"ğŸ‘€ VÃ©rification #{check_count} des tÃ¢ches en attente...")
                
                # Chercher une tÃ¢che en attente
                pending_task = self.db.get_pending_analysis()

                if pending_task:
                    logger.info(f"ğŸ¯ TÃ¢che trouvÃ©e! ID: {pending_task.id}, Type: {pending_task.analysis_type}")
                    await self.process_task(pending_task)
                else:
                    # Pas de tÃ¢che, on attend avant de vÃ©rifier Ã  nouveau
                    await asyncio.sleep(self.poll_interval_seconds)

            except Exception as e:
                logger.error(f"âŒ Erreur dans la boucle principale: {e}")
                await asyncio.sleep(60) # Attendre plus longtemps en cas d'erreur grave

    async def run_real_estate_scrape_periodically(self):
        """Lance le scraping immobilier Ã  intervalle rÃ©gulier."""
        logger.info("ğŸ¡ DÃ©marrage du scraping immobilier pÃ©riodique...")
        while self.is_running:
            try:
                # Importation de la fonction principale du nouveau scraper
                from real_estate_scraper import run_real_estate_scraper
                
                logger.info("Lancement de la tÃ¢che de scraping immobilier...")
                await run_real_estate_scraper()
                
                # Attendre 6 heures avant le prochain cycle
                logger.info("TÃ¢che de scraping immobilier terminÃ©e. Prochain cycle dans 6 heures.")
                await asyncio.sleep(6 * 3600)

            except Exception as e:
                logger.error(f"âŒ Erreur critique dans le scraping immobilier pÃ©riodique: {e}")
                await asyncio.sleep(3600) # RÃ©essayer dans 1 heure en cas d'erreur


    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Seeking Alpha nightly market brief (summary + movers + news)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def run_nightly_market_brief(self):
        """GÃ©nÃ¨re un briefing de marchÃ© tous les jours Ã  l'heure configurÃ©e."""
        logger.info("ğŸ“° DÃ©marrage du job nocturne Market Brief...")
        target_time = os.getenv("MARKET_BRIEF_TIME", "21:30")  # HH:MM Europe/Paris
        region = os.getenv("MARKET_BRIEF_REGION", "US")

        while self.is_running:
            try:
                # Calculer le dÃ©lai jusqu'au prochain crÃ©neau (Europe/Paris)
                now_utc = datetime.now(timezone.utc)
                # dÃ©calage approximatif Paris (gÃ¨re DST grossiÃ¨rement via time.localtime offset si dispo)
                paris_offset_minutes = 120  # fallback CET/CEST; pour prÃ©cision, utiliser zoneinfo
                try:
                    # tentative d'ajustement simple via time.localtime (non fiable sur serveur UTC)
                    pass
                except Exception:
                    pass

                hh, mm = [int(x) for x in target_time.split(":")]
                today_paris = now_utc + timedelta(minutes=paris_offset_minutes)
                next_run_paris = today_paris.replace(hour=hh, minute=mm, second=0, microsecond=0)
                if next_run_paris <= today_paris:
                    next_run_paris += timedelta(days=1)
                sleep_seconds = int((next_run_paris - today_paris).total_seconds())
                logger.info(f"ğŸ•™ Prochain Market Brief dans ~{sleep_seconds//60} min")
                await asyncio.sleep(max(30, sleep_seconds))

                # ExÃ©cuter le brief
                await self._execute_market_brief(region)

                # Attendre 60s pour Ã©viter double exÃ©cution si boucle rapide
                await asyncio.sleep(60)
            except Exception as e:
                logger.error(f"âŒ Erreur Market Brief loop: {e}")
                await asyncio.sleep(600)

    async def _execute_market_brief(self, region: str) -> None:
        """RÃ©cupÃ¨re les donnÃ©es Seeking Alpha, les agrÃ¨ge, sauvegarde et envoie un email."""
        logger.info("ğŸ§© GÃ©nÃ©ration du Market Brief (Seeking Alpha)...")
        from seeking_alpha_manager import (
            get_movers as sa_get_movers,
            get_news as sa_get_news,
            get_market_summary as sa_get_summary,
        )

        # Helper cache + retry
        async def fetch_cached_json(cache_key: str, ttl: int, caller, *args, **kwargs):
            # Cache Redis
            if self.redis_client:
                try:
                    cached = self.redis_client.get(cache_key)
                    if cached:
                        return json.loads(cached)
                except Exception:
                    pass
            # Retry with backoff
            delay = 1
            for attempt in range(4):
                try:
                    data = caller(*args, **kwargs)
                    if data:
                        if self.redis_client:
                            try:
                                self.redis_client.setex(cache_key, ttl, json.dumps(data))
                            except Exception:
                                pass
                        return data
                except Exception as e:
                    logger.warning(f"Tentative {attempt+1} Ã©chouÃ©e pour {cache_key}: {e}")
                await asyncio.sleep(delay)
                delay *= 2
            return None

        movers = await fetch_cached_json(f"sa:movers:{region}", 600, sa_get_movers, region)
        summary = await fetch_cached_json(f"sa:summary:{region}", 600, sa_get_summary, region)
        news = await fetch_cached_json("sa:news", 600, sa_get_news)

        # Construire le contenu texte simple
        now_paris = datetime.utcnow() + timedelta(minutes=120)
        date_str = now_paris.strftime("%Y-%m-%d")
        time_str = now_paris.strftime("%H:%M")

        def take_list(d, key):
            arr = (d or {}).get("data") if isinstance(d, dict) else None
            return arr if isinstance(arr, list) else []

        movers_list = take_list(movers, "data") or take_list(movers, "result")
        news_list = take_list(news, "data") or take_list(news, "result")

        lines = [
            f"Rapport de MarchÃ© - {date_str} {time_str} (rÃ©gion {region})",
            "",
            "RÃ©sumÃ© marchÃ©:",
        ]
        if isinstance(summary, dict):
            lines.append(json.dumps(summary.get("result") or summary.get("data") or summary, ensure_ascii=False)[:800])
        lines += ["", "Top movers:"]
        for item in (movers_list or [])[:10]:
            sym = item.get("symbol") or item.get("ticker") or item.get("name", "?")
            pct = item.get("changesPercentage") or item.get("pctChange")
            last = item.get("last") or item.get("price")
            lines.append(f" - {sym}: {pct} | {last}")
        lines += ["", "News principales:"]
        for n in (news_list or [])[:8]:
            title = n.get("title") or n.get("headline")
            url = n.get("url") or n.get("link") or "#"
            lines.append(f" - {title} - {url}")

        content = "\n".join(lines)

        # Enregistrer dans market_updates via Supabase
        try:
            from supabase import create_client
            supabase_url = os.getenv("SUPABASE_URL")
            supabase_key = os.getenv("SUPABASE_KEY")
            if supabase_url and supabase_key:
                sb = create_client(supabase_url, supabase_key)
                sb.table("market_updates").insert({
                    "content": content,
                    "date": date_str,
                    "time": time_str,
                    "trigger_type": "scheduled"
                }).execute()
                logger.info("âœ… Market Brief sauvegardÃ© dans market_updates")
            else:
                logger.warning("âš ï¸ Supabase non configurÃ©, Market Brief non sauvegardÃ©")
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde Market Brief: {e}")

        # Envoyer l'email digest (si configurÃ©)
        try:
            email_host = os.getenv("EMAIL_HOST", "smtp.gmail.com")
            email_port = int(os.getenv("EMAIL_PORT", "587"))
            email_user = os.getenv("EMAIL_USER")
            email_password = os.getenv("EMAIL_PASSWORD")
            recipients = [e.strip() for e in os.getenv("EMAIL_RECIPIENTS", "").split(",") if e.strip()]
            if email_user and email_password and recipients:
                msg = MIMEMultipart('alternative')
                msg['From'] = email_user
                msg['To'] = ", ".join(recipients)
                msg['Subject'] = f"[BONVIN] Daily Market Brief - {date_str}"
                html = f"""
                <html><body>
                <h2>Daily Market Brief ({region})</h2>
                <pre style='font-family:Inter,Arial,sans-serif; white-space:pre-wrap'>{content}</pre>
                </body></html>
                """
                msg.attach(MIMEText(html, 'html', 'utf-8'))
                with smtplib.SMTP(email_host, email_port) as server:
                    server.starttls()
                    server.login(email_user, email_password)
                    server.send_message(msg)
                logger.info("ğŸ“§ Market Brief envoyÃ© par email")
            else:
                logger.info("â„¹ï¸ Email non configurÃ©, pas d'envoi de brief")
        except Exception as e:
            logger.error(f"âŒ Erreur envoi email Market Brief: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Stock prices refresh (own currency, no conversion)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def run_stock_prices_refresh_schedule(self):
        """Met Ã  jour pÃ©riodiquement les prix des actions (sans conversion)."""
        logger.info("ğŸ“ˆ DÃ©marrage du job pÃ©riodique de mise Ã  jour des prix d'actions...")
        times_csv = os.getenv("STOCK_REFRESH_TIMES", "09:00,11:00,13:00,15:00,17:00,21:30")
        times = [t.strip() for t in times_csv.split(",") if t.strip()]
        while self.is_running:
            try:
                # Prochain crÃ©neau (approx Europe/Paris +120m)
                now_utc = datetime.now(timezone.utc)
                today_paris = now_utc + timedelta(minutes=120)
                next_runs = []
                for t in times:
                    try:
                        hh, mm = [int(x) for x in t.split(":")]
                        nr = today_paris.replace(hour=hh, minute=mm, second=0, microsecond=0)
                        if nr <= today_paris:
                            nr += timedelta(days=1)
                        next_runs.append(nr)
                    except Exception:
                        continue
                if not next_runs:
                    await asyncio.sleep(3600)
                    continue
                next_run_paris = min(next_runs)
                sleep_seconds = int((next_run_paris - today_paris).total_seconds())
                logger.info(f"ğŸ•’ Prochaine MAJ prix actions dans ~{max(0, sleep_seconds)//60} min")
                await asyncio.sleep(max(30, sleep_seconds))

                # ExÃ©cuter la mise Ã  jour
                await self._refresh_all_stocks()
                await asyncio.sleep(60)
            except Exception as e:
                logger.error(f"âŒ Erreur loop MAJ actions: {e}")
                await asyncio.sleep(600)

    async def _refresh_all_stocks(self):
        """RafraÃ®chit tous les prix d'actions via StockAPIManager et sauvegarde dans Supabase."""
        try:
            from supabase import create_client
            supabase_url = os.getenv("SUPABASE_URL")
            supabase_key = os.getenv("SUPABASE_KEY")
            if not (supabase_url and supabase_key):
                logger.warning("âš ï¸ Supabase non configurÃ©, MAJ des prix ignorÃ©e")
                return
            sb = create_client(supabase_url, supabase_key)

            resp = sb.table('items').select('*').eq('category', 'Actions').execute()
            rows = resp.data or []
            if not rows:
                logger.info("â„¹ï¸ Aucune action Ã  mettre Ã  jour")
                return
            updated = 0
            failed = 0
            for row in rows:
                symbol = row.get('stock_symbol')
                if not symbol:
                    continue
                try:
                    data = stock_api_manager.get_stock_price(symbol, force_refresh=True)
                    if not data or not data.get('price'):
                        failed += 1
                        continue
                    price = data.get('price')
                    qty = row.get('stock_quantity') or 1
                    update_data = {
                        'current_price': price,
                        'current_value': price * qty,
                        'last_price_update': datetime.utcnow().isoformat(),
                        'stock_volume': data.get('volume'),
                        'stock_pe_ratio': data.get('pe_ratio'),
                        'stock_52_week_high': data.get('fifty_two_week_high'),
                        'stock_52_week_low': data.get('fifty_two_week_low'),
                        'stock_change': data.get('change'),
                        'stock_change_percent': data.get('change_percent'),
                        'stock_average_volume': data.get('volume'),
                        'stock_currency': data.get('currency')
                    }
                    sb.table('items').update(update_data).eq('id', row['id']).execute()
                    updated += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ Echec MAJ {symbol}: {e}")
                    failed += 1
            logger.info(f"âœ… MAJ prix actions terminÃ©e: {updated} ok, {failed} Ã©checs")
        except Exception as e:
            logger.error(f"âŒ Erreur _refresh_all_stocks: {e}")


    def stop(self):
        """ArrÃªte proprement le worker."""
        logger.info("ğŸ›‘ ArrÃªt du Background Worker...")
        self.is_running = False
        if hasattr(self.scraper, 'cleanup'):
            self.scraper.cleanup()

async def main():
    """Point d'entrÃ©e principal."""
    worker = MarketAnalysisWorker()
    try:
        worker.initialize()
        # Lancer uniquement la file d'analyses marchÃ© (pas de tÃ¢ches auto)
        market_analysis_task = asyncio.create_task(worker.run_continuous_loop())
        await asyncio.gather(market_analysis_task)
    except (KeyboardInterrupt, SystemExit):
        logger.info("ArrÃªt initiÃ©.")
    except Exception as e:
        logger.error(f"âŒ Le worker s'est arrÃªtÃ© en raison d'une erreur fatale: {e}")
    finally:
        worker.stop()

if __name__ == "__main__":
    asyncio.run(main())
