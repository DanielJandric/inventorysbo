#!/usr/bin/env python3
"""
Test d'ex√©cution du Background Worker
"""

import os
import asyncio
import logging
import time
from datetime import datetime
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_scraper_initialization():
    """Test de l'initialisation du scraper"""
    try:
        logger.info("üß™ Test 1: Initialisation du ScrapingBee Scraper")
        
        from scrapingbee_scraper import get_scrapingbee_scraper
        scraper = get_scrapingbee_scraper()
        
        # Test d'initialisation synchrone
        scraper.initialize_sync()
        logger.info("‚úÖ Initialisation synchrone r√©ussie")
        
        # Test d'initialisation asynchrone
        await scraper.initialize()
        logger.info("‚úÖ Initialisation asynchrone r√©ussie")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur initialisation scraper: {e}")
        return False

async def test_task_creation():
    """Test de cr√©ation de t√¢che"""
    try:
        logger.info("üß™ Test 2: Cr√©ation de t√¢che de scraping")
        
        # Utiliser l'instance globale du scraper
        from app import get_global_scraper
        scraper = get_global_scraper()
        
        # Initialiser
        await scraper.initialize()
        
        # Cr√©er une t√¢che
        prompt = "Test de cr√©ation de t√¢che"
        task_id = await scraper.create_scraping_task(prompt, 2)
        
        logger.info(f"‚úÖ T√¢che cr√©√©e avec l'ID: {task_id}")
        return task_id
        
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation t√¢che: {e}")
        return None

async def test_task_execution(task_id):
    """Test d'ex√©cution de t√¢che"""
    try:
        logger.info("üß™ Test 3: Ex√©cution de t√¢che de scraping")
        
        # Utiliser l'instance globale du scraper
        from app import get_global_scraper
        scraper = get_global_scraper()
        
        # Initialiser
        await scraper.initialize()
        
        # Ex√©cuter la t√¢che
        start_time = time.time()
        result = await scraper.execute_scraping_task(task_id)
        execution_time = time.time() - start_time
        
        logger.info(f"‚úÖ T√¢che ex√©cut√©e en {execution_time:.2f} secondes")
        logger.info(f"üìä R√©sultat: {result}")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur ex√©cution t√¢che: {e}")
        return None

async def test_database_integration():
    """Test d'int√©gration avec la base de donn√©es"""
    try:
        logger.info("üß™ Test 4: Int√©gration base de donn√©es")
        
        from market_analysis_db import get_market_analysis_db, MarketAnalysis
        
        db = get_market_analysis_db()
        
        if not db.is_connected():
            logger.error("‚ùå Pas de connexion √† la base de donn√©es")
            return False
        
        # Cr√©er une analyse de test
        test_analysis = MarketAnalysis(
            analysis_type='test',
            summary='Test d\'int√©gration',
            key_points=['Test r√©ussi'],
            worker_status='completed'
        )
        
        analysis_id = db.save_analysis(test_analysis)
        
        if analysis_id:
            logger.info(f"‚úÖ Analyse de test sauvegard√©e avec l'ID: {analysis_id}")
            return True
        else:
            logger.error("‚ùå √âchec de sauvegarde de l'analyse")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Erreur int√©gration base de donn√©es: {e}")
        return False

async def test_full_workflow():
    """Test du workflow complet"""
    try:
        logger.info("üß™ Test 5: Workflow complet")
        
        from app import get_global_scraper
        from market_analysis_db import get_market_analysis_db, MarketAnalysis
        
        # Initialiser le scraper
        scraper = get_global_scraper()
        await scraper.initialize()
        
        # Cr√©er une t√¢che
        prompt = "R√©sume moi parfaitement et d'une fa√ßon exhaustive la situation sur les march√©s financiers aujourd'hui. Aussi, je veux un focus particulier sur l'IA."
        task_id = await scraper.create_scraping_task(prompt, 2)
        
        # Ex√©cuter la t√¢che
        start_time = time.time()
        result = await scraper.execute_scraping_task(task_id)
        execution_time = time.time() - start_time
        
        if "error" in result:
            logger.error(f"‚ùå Erreur dans le workflow: {result['error']}")
            return False
        
        # Sauvegarder dans la base de donn√©es
        db = get_market_analysis_db()
        analysis = MarketAnalysis(
            analysis_type='test_workflow',
            summary=result.get('summary'),
            key_points=result.get('key_points', []),
            structured_data=result.get('structured_data', {}),
            insights=result.get('insights', []),
            risks=result.get('risks', []),
            opportunities=result.get('opportunities', []),
            sources=result.get('sources', []),
            confidence_score=result.get('confidence_score', 0.0),
            worker_status='completed',
            processing_time_seconds=int(execution_time)
        )
        
        analysis_id = db.save_analysis(analysis)
        
        if analysis_id:
            logger.info(f"‚úÖ Workflow complet r√©ussi - Analyse sauvegard√©e avec l'ID: {analysis_id}")
            logger.info(f"‚è±Ô∏è Temps d'ex√©cution: {execution_time:.2f} secondes")
            return True
        else:
            logger.error("‚ùå √âchec de sauvegarde dans le workflow")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Erreur workflow complet: {e}")
        return False

async def main():
    """Fonction principale"""
    logger.info("üöÄ Test d'ex√©cution du Background Worker")
    logger.info("=" * 60)
    
    # Test 1: Initialisation
    success1 = await test_scraper_initialization()
    
    # Test 2: Cr√©ation de t√¢che
    task_id = await test_task_creation()
    success2 = task_id is not None
    
    # Test 3: Ex√©cution de t√¢che (si cr√©ation r√©ussie)
    success3 = False
    if task_id:
        result = await test_task_execution(task_id)
        success3 = result is not None and "error" not in result
    
    # Test 4: Base de donn√©es
    success4 = await test_database_integration()
    
    # Test 5: Workflow complet
    success5 = await test_full_workflow()
    
    logger.info("\n" + "=" * 60)
    logger.info("üìä R√©sultats des tests:")
    logger.info(f"   Test 1 (Initialisation): {'‚úÖ' if success1 else '‚ùå'}")
    logger.info(f"   Test 2 (Cr√©ation t√¢che): {'‚úÖ' if success2 else '‚ùå'}")
    logger.info(f"   Test 3 (Ex√©cution t√¢che): {'‚úÖ' if success3 else '‚ùå'}")
    logger.info(f"   Test 4 (Base de donn√©es): {'‚úÖ' if success4 else '‚ùå'}")
    logger.info(f"   Test 5 (Workflow complet): {'‚úÖ' if success5 else '‚ùå'}")
    
    if all([success1, success2, success3, success4, success5]):
        logger.info("üéâ Tous les tests r√©ussis ! Le Background Worker devrait fonctionner.")
    else:
        logger.error("‚ùå Certains tests ont √©chou√©. V√©rifiez les logs ci-dessus.")
    
    return all([success1, success2, success3, success4, success5])

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1) 