"""
Scraper automatique SNB avec ScrapingBee
Collecte automatiquement : CPI (OFS), KOF, OIS approximatif, pr√©visions BNS

Configuration requise :
- SCRAPINGBEE_API_KEY dans .env
- SNB_API_BASE_URL (optionnel, d√©faut: https://inventorysbo.onrender.com)

Usage:
    python snb_auto_scraper.py --daily     # Collecte quotidienne (OIS)
    python snb_auto_scraper.py --monthly   # Collecte mensuelle (CPI + KOF)
    python snb_auto_scraper.py --quarterly # Collecte trimestrielle (BNS)
    python snb_auto_scraper.py --all       # Tout collecter
"""

import os
import sys
import json
import re
import requests
from datetime import datetime, date
from typing import Dict, Any, Optional, List
import argparse
from dotenv import load_dotenv

load_dotenv()

# Configuration
SCRAPINGBEE_API_KEY = os.getenv("SCRAPINGBEE_API_KEY")
API_BASE_URL = os.getenv("SNB_API_BASE_URL", "https://inventorysbo.onrender.com")
NOTIFICATION_EMAIL = os.getenv("SNB_NOTIFICATION_EMAIL")  # Optionnel

# URLs sources
OFS_CPI_URL = "https://www.bfs.admin.ch/bfs/fr/home/statistiques/prix/indice-prix-consommation.html"
KOF_BAROMETER_URL = "https://kof.ethz.ch/en/forecasts-and-indicators/indicators/kof-economic-barometer.html"
SNB_MPA_URL = "https://www.snb.ch/en/the-snb/mandates-goals/monetary-policy/monetary-policy-assessment"


class SNBAutoScraper:
    """Scraper automatique pour les donn√©es SNB"""
    
    def __init__(self):
        if not SCRAPINGBEE_API_KEY:
            print("‚ö†Ô∏è  SCRAPINGBEE_API_KEY non configur√©e, mode simulation")
            self.simulation_mode = True
        else:
            self.simulation_mode = False
        
        self.results = []
        self.errors = []
    
    def scrape_with_scrapingbee(self, url: str, extract_rules: Dict = None) -> Optional[Dict]:
        """Scrape une URL avec ScrapingBee"""
        if self.simulation_mode:
            print(f"üß™ Mode simulation pour {url}")
            return None
        
        try:
            params = {
                "api_key": SCRAPINGBEE_API_KEY,
                "url": url,
                "render_js": "true",
                "premium_proxy": "true",
                "country_code": "ch"
            }
            
            if extract_rules:
                params["extract_rules"] = json.dumps(extract_rules)
            
            response = requests.get(
                "https://app.scrapingbee.com/api/v1/",
                params=params,
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json() if extract_rules else {"content": response.text}
            else:
                print(f"‚ùå ScrapingBee erreur {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Erreur scraping: {e}")
            return None
    
    def collect_cpi(self) -> Optional[Dict[str, Any]]:
        """Collecte automatique du CPI depuis OFS"""
        print("\nüìä Collecte CPI (OFS)...")
        
        # Extraction rules pour ScrapingBee
        extract_rules = {
            "yoy_text": {
                "selector": "body",
                "type": "text"
            }
        }
        
        data = self.scrape_with_scrapingbee(OFS_CPI_URL, extract_rules)
        
        if not data and not self.simulation_mode:
            self.errors.append("CPI: Scraping √©chou√©")
            return None
        
        # Mode simulation : valeurs par d√©faut
        if self.simulation_mode:
            print("üß™ Utilisation de valeurs simul√©es")
            yoy_pct = 0.7  # Exemple
            as_of = date.today().replace(day=1)
        else:
            # Parser le texte pour extraire YoY
            text = data.get("yoy_text", "")
            
            # Regex pour trouver "X.X%" ou "X,X%"
            match = re.search(r'(\d+[.,]\d+)\s*%.*?(sur un an|year-on-year|annual)', text, re.IGNORECASE)
            
            if match:
                yoy_str = match.group(1).replace(',', '.')
                yoy_pct = float(yoy_str)
                as_of = date.today().replace(day=1)
            else:
                print("‚ö†Ô∏è  Impossible d'extraire YoY, utilisation valeur par d√©faut")
                yoy_pct = 0.5
                as_of = date.today().replace(day=1)
        
        payload = {
            "provider": "BFS",
            "as_of": as_of.isoformat(),
            "yoy_pct": yoy_pct,
            "mm_pct": None,
            "source_url": OFS_CPI_URL,
            "idempotency_key": f"bfs-{as_of.strftime('%Y-%m')}-auto"
        }
        
        print(f"‚úÖ CPI collect√©: {yoy_pct}% YoY au {as_of}")
        return payload
    
    def collect_kof(self) -> Optional[Dict[str, Any]]:
        """Collecte automatique du KOF Barometer"""
        print("\nüìà Collecte KOF Barometer...")
        
        extract_rules = {
            "barometer_text": {
                "selector": "body",
                "type": "text"
            }
        }
        
        data = self.scrape_with_scrapingbee(KOF_BAROMETER_URL, extract_rules)
        
        if not data and not self.simulation_mode:
            self.errors.append("KOF: Scraping √©chou√©")
            return None
        
        # Mode simulation
        if self.simulation_mode:
            print("üß™ Utilisation de valeurs simul√©es")
            barometer = 101.2  # Exemple
            as_of = date.today()
        else:
            # Parser pour trouver la valeur du barom√®tre (typiquement 90-110)
            text = data.get("barometer_text", "")
            match = re.search(r'(\d{2,3}[.,]\d+)\s*(points?|Punkte)', text)
            
            if match:
                bar_str = match.group(1).replace(',', '.')
                barometer = float(bar_str)
                as_of = date.today()
            else:
                print("‚ö†Ô∏è  Impossible d'extraire barometer, utilisation valeur par d√©faut")
                barometer = 100.0
                as_of = date.today()
        
        payload = {
            "provider": "KOF",
            "as_of": as_of.isoformat(),
            "barometer": barometer,
            "source_url": KOF_BAROMETER_URL,
            "idempotency_key": f"kof-{as_of.strftime('%Y-%m')}-auto"
        }
        
        print(f"‚úÖ KOF collect√©: {barometer} au {as_of}")
        return payload
    
    def collect_ois_from_eurex(self) -> Optional[Dict[str, Any]]:
        """
        Collecte la courbe OIS depuis les futures SARON 3M d'Eurex
        
        Source: https://www.eurex.com/ex-en/markets/int/mon/saron-futures/saron/3M-SARON-Futures-1410330
        """
        print("\nüíπ Collecte courbe OIS depuis Eurex (3M SARON Futures)...")
        
        eurex_url = "https://www.eurex.com/ex-en/markets/int/mon/saron-futures/saron/3M-SARON-Futures-1410330"
        
        # Scraper avec ScrapingBee
        extract_rules = {
            "order_book": {
                "selector": "#orderBookTable",
                "type": "table"
            },
            "prices_text": {
                "selector": "body",
                "type": "text"
            }
        }
        
        data = self.scrape_with_scrapingbee(eurex_url, extract_rules)
        
        if not data and not self.simulation_mode:
            print("‚ö†Ô∏è  Scraping Eurex √©chou√©, utilisation approximation...")
            return self.collect_ois_approximation()
        
        if self.simulation_mode:
            print("üß™ Mode simulation: utilisation approximation")
            return self.collect_ois_approximation()
        
        # Parser les donn√©es Eurex
        try:
            # Les futures SARON sont cot√©s en termes de prix (100 - taux implicite)
            # Exemple: Prix 99.50 ‚Üí taux implicite = 0.50%
            
            # Extraire les prix des contrats par √©ch√©ance
            # Format Eurex: contrats trimestriels (Mar, Jun, Sep, Dec)
            text = data.get("prices_text", "")
            
            # Regex pour trouver les prix (format: 99.XXX)
            # Les contrats sont list√©s par √©ch√©ance (le plus proche en premier)
            matches = re.findall(r'(99\.\d{2,3}|100\.\d{2,3})', text)
            
            if not matches or len(matches) < 4:
                print("‚ö†Ô∏è  Pas assez de donn√©es Eurex, utilisation approximation")
                return self.collect_ois_approximation()
            
            # Convertir prix en taux implicites
            # Prix du futures = 100 - taux implicite (en %)
            futures_prices = [float(m) for m in matches[:8]]  # 8 premiers contrats (2 ans)
            implicit_rates = [100.0 - price for price in futures_prices]
            
            # Mapper aux tenors (contrats trimestriels)
            # Contrat 1 = 3M, Contrat 2 = 6M, Contrat 3 = 9M, etc.
            points = []
            for i, rate in enumerate(implicit_rates[:8]):
                tenor = (i + 1) * 3  # 3, 6, 9, 12, 15, 18, 21, 24 mois
                if tenor <= 24:
                    points.append({
                        "tenor_months": tenor,
                        "rate_pct": rate
                    })
            
            # S'assurer qu'on a au moins 6 points (3, 6, 9, 12, 18, 24)
            if len(points) < 6:
                print("‚ö†Ô∏è  Pas assez de points OIS, utilisation approximation")
                return self.collect_ois_approximation()
            
            as_of = date.today()
            
            payload = {
                "as_of": as_of.isoformat(),
                "points": points,
                "source_url": eurex_url,
                "idempotency_key": f"ois-{as_of.isoformat()}-eurex"
            }
            
            print(f"‚úÖ OIS Eurex collect√©: {len(points)} points")
            print(f"   3M: {points[0]['rate_pct']:.3f}% | 12M: {points[3]['rate_pct']:.3f}%")
            return payload
            
        except Exception as e:
            print(f"‚ùå Erreur parsing Eurex: {e}")
            print("   Fallback vers approximation...")
            return self.collect_ois_approximation()
    
    def collect_ois_approximation(self) -> Optional[Dict[str, Any]]:
        """
        G√©n√®re une courbe OIS approximative bas√©e sur le taux directeur BNS actuel
        
        Fallback si scraping Eurex √©choue
        """
        print("\nüíπ G√©n√©ration courbe OIS approximative (fallback)...")
        
        # Taux directeur BNS actuel (√† adapter selon l'actualit√©)
        policy_rate = 0.50  # Exemple: 0.50% (√† jour dec 2024)
        
        # Approximation : courbe plate avec l√©g√®re pente
        points = [
            {"tenor_months": 3, "rate_pct": policy_rate},
            {"tenor_months": 6, "rate_pct": policy_rate + 0.05},
            {"tenor_months": 9, "rate_pct": policy_rate + 0.10},
            {"tenor_months": 12, "rate_pct": policy_rate + 0.15},
            {"tenor_months": 18, "rate_pct": policy_rate + 0.20},
            {"tenor_months": 24, "rate_pct": policy_rate + 0.25}
        ]
        
        as_of = date.today()
        
        payload = {
            "as_of": as_of.isoformat(),
            "points": points,
            "source_url": "https://www.snb.ch (approximation)",
            "idempotency_key": f"ois-{as_of.isoformat()}-approx"
        }
        
        print(f"‚ö†Ô∏è  OIS approximatif: {policy_rate}% (taux directeur)")
        return payload
    
    def collect_snb_forecast(self) -> Optional[Dict[str, Any]]:
        """
        Collecte les pr√©visions BNS (trimestriel)
        
        Note: Le parsing de PDF est complexe. Pour l'instant, utilise des valeurs par d√©faut.
        TODO: Impl√©menter parser PDF ou attendre publication structur√©e
        """
        print("\nüè¶ Collecte pr√©visions BNS...")
        
        # V√©rifier si on est dans un mois de MPA (mars, juin, sept, d√©c)
        current_month = date.today().month
        if current_month not in [3, 6, 9, 12]:
            print("‚ÑπÔ∏è  Pas de MPA ce mois-ci (seulement mars, juin, sept, d√©c)")
            return None
        
        # Mode simulation : utiliser derni√®res pr√©visions connues
        print("üß™ Utilisation de pr√©visions par d√©faut (n√©cessite parsing PDF manuel)")
        
        current_year = date.today().year
        meeting_date = date.today()
        
        # Pr√©visions exemple (√† mettre √† jour manuellement apr√®s chaque MPA)
        forecast = {
            str(current_year): 0.7,
            str(current_year + 1): 1.0,
            str(current_year + 2): 1.2
        }
        
        payload = {
            "meeting_date": meeting_date.isoformat(),
            "forecast": forecast,
            "source_url": SNB_MPA_URL,
            "pdf_url": f"{SNB_MPA_URL}/mpa-{meeting_date.strftime('%Y-%m')}.pdf",
            "idempotency_key": f"snb-mpa-{meeting_date.isoformat()}-auto"
        }
        
        print(f"‚úÖ Pr√©visions BNS: {forecast}")
        return payload
    
    def ingest_data(self, endpoint: str, data: Dict[str, Any]) -> bool:
        """Envoie les donn√©es vers l'API"""
        try:
            url = f"{API_BASE_URL}/api/snb/ingest/{endpoint}"
            print(f"üì§ Envoi vers {url}")
            
            response = requests.post(url, json=data, timeout=30)
            
            if response.status_code in [200, 201]:
                print("‚úÖ Donn√©es ing√©r√©es")
                self.results.append(f"{endpoint}: OK")
                return True
            elif response.status_code == 409:
                print("‚ÑπÔ∏è  Donn√©es d√©j√† existantes")
                self.results.append(f"{endpoint}: D√©j√† existant")
                return True
            else:
                print(f"‚ùå Erreur {response.status_code}: {response.text}")
                self.errors.append(f"{endpoint}: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur d'envoi: {e}")
            self.errors.append(f"{endpoint}: {str(e)}")
            return False
    
    def run_model(self) -> bool:
        """Lance le calcul du mod√®le"""
        try:
            url = f"{API_BASE_URL}/api/snb/model/run"
            print(f"\nüßÆ Calcul du mod√®le...")
            
            response = requests.post(url, json={}, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print("‚úÖ Mod√®le calcul√©")
                    output = result.get("result", {})
                    print(f"   ‚Üí i* = {output.get('i_star_next_pct', 0):.2f}%")
                    probs = output.get('probs', {})
                    print(f"   ‚Üí Hold = {probs.get('hold', 0):.1%}")
                    self.results.append("Mod√®le: Calcul√©")
                    return True
            
            print(f"‚ùå Erreur calcul")
            self.errors.append("Mod√®le: √âchec calcul")
            return False
            
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
            self.errors.append(f"Mod√®le: {str(e)}")
            return False
    
    def send_notification(self):
        """Envoie une notification par email (optionnel)"""
        if not NOTIFICATION_EMAIL:
            return
        
        # TODO: Impl√©menter envoi email via SMTP ou service
        print(f"üìß Notification envoy√©e √† {NOTIFICATION_EMAIL}")
    
    def run_daily_collection(self):
        """Collecte quotidienne (OIS seulement)"""
        print("üåÖ === COLLECTE QUOTIDIENNE ===")
        
        # OIS depuis Eurex (fallback vers approximation si √©chec)
        ois_data = self.collect_ois_from_eurex()
        if ois_data:
            self.ingest_data("ois", ois_data)
        
        # Relancer le mod√®le
        self.run_model()
    
    def run_monthly_collection(self):
        """Collecte mensuelle (CPI + KOF)"""
        print("üìÖ === COLLECTE MENSUELLE ===")
        
        # CPI
        cpi_data = self.collect_cpi()
        if cpi_data:
            self.ingest_data("cpi", cpi_data)
        
        # KOF
        kof_data = self.collect_kof()
        if kof_data:
            self.ingest_data("kof", kof_data)
        
        # OIS depuis Eurex (fallback vers approximation si √©chec)
        ois_data = self.collect_ois_from_eurex()
        if ois_data:
            self.ingest_data("ois", ois_data)
        
        # Relancer le mod√®le
        self.run_model()
    
    def run_quarterly_collection(self):
        """Collecte trimestrielle (BNS)"""
        print("üìÜ === COLLECTE TRIMESTRIELLE ===")
        
        # Pr√©visions BNS
        snb_data = self.collect_snb_forecast()
        if snb_data:
            self.ingest_data("snb-forecast", snb_data)
        
        # Tout recalculer
        self.run_monthly_collection()
    
    def print_summary(self):
        """Affiche le r√©sum√©"""
        print("\n" + "="*60)
        print("üìä R√âSUM√â DE LA COLLECTE")
        print("="*60)
        
        if self.results:
            print("\n‚úÖ Succ√®s:")
            for r in self.results:
                print(f"   ‚Ä¢ {r}")
        
        if self.errors:
            print("\n‚ùå Erreurs:")
            for e in self.errors:
                print(f"   ‚Ä¢ {e}")
        
        if not self.errors:
            print("\nüéâ Collecte r√©ussie √† 100%")
        else:
            print(f"\n‚ö†Ô∏è  {len(self.errors)} erreur(s)")
        
        print(f"\nüåê Voir r√©sultats: {API_BASE_URL}/snb-taux")
        print("="*60)


def main():
    parser = argparse.ArgumentParser(description="Scraper automatique SNB")
    parser.add_argument("--daily", action="store_true", help="Collecte quotidienne (OIS)")
    parser.add_argument("--monthly", action="store_true", help="Collecte mensuelle (CPI + KOF)")
    parser.add_argument("--quarterly", action="store_true", help="Collecte trimestrielle (BNS)")
    parser.add_argument("--all", action="store_true", help="Tout collecter")
    
    args = parser.parse_args()
    
    if not any(vars(args).values()):
        parser.print_help()
        return
    
    scraper = SNBAutoScraper()
    
    try:
        if args.all or args.quarterly:
            scraper.run_quarterly_collection()
        elif args.monthly:
            scraper.run_monthly_collection()
        elif args.daily:
            scraper.run_daily_collection()
        
        scraper.print_summary()
        scraper.send_notification()
        
        # Exit code selon succ√®s
        sys.exit(0 if not scraper.errors else 1)
        
    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

