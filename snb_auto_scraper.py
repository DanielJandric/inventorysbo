"""
Scraper automatique SNB avec ScrapingBee
Collecte automatiquement : CPI (OFS), KOF, OIS approximatif, pr√©visions BNS

Configuration requise :
- SCRAPINGBEE_API_KEY dans .env
- SNB_API_BASE_URL (optionnel, d√©faut: https://inventorysbo.onrender.com)

Usage:
    python snb_auto_scraper.py --daily     # Collecte quotidienne (OIS)
    python snb_auto_scraper.py --monthly   # Collecte mensuelle (CPI + KOF)
    python snb_auto_scraper.py --quarterly # Collecte trimestrielle (BNS)
    python snb_auto_scraper.py --all       # Tout collecter
"""

import os
import sys
import json
import re
import requests
from datetime import datetime, date
from typing import Dict, Any, Optional, List
import argparse
from dotenv import load_dotenv

load_dotenv()

# Configuration
SCRAPINGBEE_API_KEY = os.getenv("SCRAPINGBEE_API_KEY")
API_BASE_URL = os.getenv("SNB_API_BASE_URL", "https://inventorysbo.onrender.com")
NOTIFICATION_EMAIL = os.getenv("SNB_NOTIFICATION_EMAIL")  # Optionnel

# URLs sources
OFS_CPI_URL = "https://www.bfs.admin.ch/bfs/fr/home/statistiques/prix/indice-prix-consommation.html"
KOF_BAROMETER_URL = "https://kof.ethz.ch/en/forecasts-and-indicators/indicators/kof-economic-barometer.html"
SNB_MPA_URL = "https://www.snb.ch/en/the-snb/mandates-goals/monetary-policy/monetary-policy-assessment"


class SNBAutoScraper:
    """Scraper automatique pour les donn√©es SNB"""
    
    def __init__(self):
        if not SCRAPINGBEE_API_KEY:
            print("‚ö†Ô∏è  SCRAPINGBEE_API_KEY non configur√©e, mode simulation")
            self.simulation_mode = True
        else:
            self.simulation_mode = False
        
        self.results = []
        self.errors = []
    
    def scrape_with_scrapingbee(self, url: str) -> Optional[Dict]:
        """Scrape une URL avec ScrapingBee"""
        if self.simulation_mode:
            print(f"üß™ Mode simulation pour {url}")
            return None
        
        try:
            # Param√®tres ScrapingBee (format officiel)
            params = {
                "api_key": SCRAPINGBEE_API_KEY,
                "url": url,
                "render_js": "true"
            }
            
            response = requests.get(
                "https://app.scrapingbee.com/api/v1",  # Pas de slash final
                params=params,
                timeout=60
            )
            
            if response.status_code == 200:
                # Retourner le contenu HTML brut
                return {"content": response.text}
            else:
                # Afficher le d√©tail de l'erreur
                print(f"‚ùå ScrapingBee erreur {response.status_code}")
                print(f"   Body: {response.text[:300]}")
                return None
                
        except Exception as e:
            print(f"‚ùå Erreur scraping: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def collect_cpi(self) -> Optional[Dict[str, Any]]:
        """Collecte automatique du CPI depuis OFS"""
        print("\nüìä Collecte CPI (OFS)...")
        
        # Scraping du HTML brut
        data = self.scrape_with_scrapingbee(OFS_CPI_URL)
        
        if not data and not self.simulation_mode:
            self.errors.append("CPI: Scraping √©chou√©")
            return None
        
        # Mode simulation : valeurs par d√©faut
        if self.simulation_mode:
            print("üß™ Utilisation de valeurs simul√©es")
            yoy_pct = 0.7  # Exemple
            as_of = date.today().replace(day=1)
        else:
            # Parser le HTML content pour extraire YoY
            html_content = data.get("content", "")
            
            # Regex pour trouver "X.X%" ou "X,X%" avec contexte "sur un an"
            match = re.search(r'(\d+[.,]\d+)\s*%.*?(sur un an|ann√©e|year-on-year|j√§hrlich)', html_content, re.IGNORECASE | re.DOTALL)
            
            if match:
                yoy_str = match.group(1).replace(',', '.')
                yoy_pct = float(yoy_str)
                as_of = date.today().replace(day=1)
                print(f"   Extrait du HTML: {yoy_pct}%")
            else:
                print("‚ö†Ô∏è  Impossible d'extraire YoY du HTML, utilisation valeur par d√©faut")
                yoy_pct = 0.7
                as_of = date.today().replace(day=1)
        
        payload = {
            "provider": "BFS",
            "as_of": as_of.isoformat(),
            "yoy_pct": yoy_pct,
            "mm_pct": None,
            "source_url": OFS_CPI_URL,
            "idempotency_key": f"bfs-{as_of.strftime('%Y-%m')}-auto"
        }
        
        print(f"‚úÖ CPI collect√©: {yoy_pct}% YoY au {as_of}")
        return payload
    
    def collect_kof(self) -> Optional[Dict[str, Any]]:
        """Collecte automatique du KOF Barometer"""
        print("\nüìà Collecte KOF Barometer...")
        
        # Scraping du HTML brut
        data = self.scrape_with_scrapingbee(KOF_BAROMETER_URL)
        
        if not data and not self.simulation_mode:
            self.errors.append("KOF: Scraping √©chou√©")
            return None
        
        # Mode simulation
        if self.simulation_mode:
            print("üß™ Utilisation de valeurs simul√©es")
            barometer = 101.2  # Exemple
            as_of = date.today()
        else:
            # Parser le HTML pour trouver la valeur du barom√®tre (typiquement 90-110)
            html_content = data.get("content", "")
            match = re.search(r'(\d{2,3}[.,]\d+)\s*(points?|Punkte|punti)', html_content, re.IGNORECASE)
            
            if match:
                bar_str = match.group(1).replace(',', '.')
                barometer = float(bar_str)
                as_of = date.today()
                print(f"   Extrait du HTML: {barometer}")
            else:
                print("‚ö†Ô∏è  Impossible d'extraire barometer du HTML, utilisation valeur par d√©faut")
                barometer = 101.2
                as_of = date.today()
        
        payload = {
            "provider": "KOF",
            "as_of": as_of.isoformat(),
            "barometer": barometer,
            "source_url": KOF_BAROMETER_URL,
            "idempotency_key": f"kof-{as_of.strftime('%Y-%m')}-auto"
        }
        
        print(f"‚úÖ KOF collect√©: {barometer} au {as_of}")
        return payload
    
    def collect_ois_from_eurex(self) -> Optional[Dict[str, Any]]:
        """
        Collecte la courbe OIS depuis les futures SARON 3M d'Eurex
        
        Source: https://www.eurex.com/ex-en/markets/int/mon/saron-futures/saron/3M-SARON-Futures-1410330
        """
        print("\nüíπ Collecte courbe OIS depuis Eurex (3M SARON Futures)...")
        
        eurex_url = "https://www.eurex.com/ex-en/markets/int/mon/saron-futures/saron/3M-SARON-Futures-1410330"
        
        # Scraping du HTML brut
        data = self.scrape_with_scrapingbee(eurex_url)
        
        if not data and not self.simulation_mode:
            print("‚ö†Ô∏è  Scraping Eurex √©chou√©, utilisation approximation...")
            return self.collect_ois_approximation()
        
        if self.simulation_mode:
            print("üß™ Mode simulation: utilisation approximation")
            return self.collect_ois_approximation()
        
        # Parser les donn√©es Eurex
        try:
            # Les futures SARON sont cot√©s en termes de prix (100 - taux implicite)
            # Exemple: Prix 99.50 ‚Üí taux implicite = 0.50%
            
            # Extraire les prix des contrats par √©ch√©ance
            # Format Eurex: contrats trimestriels (Mar, Jun, Sep, Dec)
            html_content = data.get("content", "")
            
            # Regex pour trouver les prix (format: 99.XXX ou 100.XXX)
            # Les contrats sont list√©s par √©ch√©ance (le plus proche en premier)
            matches = re.findall(r'(99\.\d{2,3}|100\.\d{2,3})', html_content)
            
            if not matches or len(matches) < 4:
                print("‚ö†Ô∏è  Pas assez de donn√©es Eurex, utilisation approximation")
                return self.collect_ois_approximation()
            
            # Convertir prix en taux implicites
            # Prix du futures = 100 - taux implicite (en %)
            futures_prices = [float(m) for m in matches[:8]]  # 8 premiers contrats (2 ans)
            implicit_rates = [100.0 - price for price in futures_prices]
            
            # Mapper aux tenors (contrats trimestriels)
            # Contrat 1 = 3M, Contrat 2 = 6M, Contrat 3 = 9M, etc.
            points = []
            for i, rate in enumerate(implicit_rates[:8]):
                tenor = (i + 1) * 3  # 3, 6, 9, 12, 15, 18, 21, 24 mois
                if tenor <= 24:
                    points.append({
                        "tenor_months": tenor,
                        "rate_pct": rate
                    })
            
            # S'assurer qu'on a au moins 6 points (3, 6, 9, 12, 18, 24)
            if len(points) < 6:
                print("‚ö†Ô∏è  Pas assez de points OIS, utilisation approximation")
                return self.collect_ois_approximation()
            
            as_of = date.today()
            
            payload = {
                "as_of": as_of.isoformat(),
                "points": points,
                "source_url": eurex_url,
                "idempotency_key": f"ois-{as_of.isoformat()}-eurex"
            }
            
            print(f"‚úÖ OIS Eurex collect√©: {len(points)} points")
            print(f"   3M: {points[0]['rate_pct']:.3f}% | 12M: {points[3]['rate_pct']:.3f}%")
            return payload
            
        except Exception as e:
            print(f"‚ùå Erreur parsing Eurex: {e}")
            print("   Fallback vers approximation...")
            return self.collect_ois_approximation()
    
    def collect_ois_approximation(self) -> Optional[Dict[str, Any]]:
        """
        G√©n√®re une courbe OIS approximative bas√©e sur le taux directeur BNS actuel
        
        Fallback si scraping Eurex √©choue
        """
        print("\nüíπ G√©n√©ration courbe OIS approximative (fallback)...")
        
        # Taux directeur BNS actuel (MPA 25 septembre 2025)
        policy_rate = 0.00  # 0.00% - Maintenu √† 0%
        
        # Approximation : courbe plate avec l√©g√®re pente
        points = [
            {"tenor_months": 3, "rate_pct": policy_rate},
            {"tenor_months": 6, "rate_pct": policy_rate + 0.05},
            {"tenor_months": 9, "rate_pct": policy_rate + 0.10},
            {"tenor_months": 12, "rate_pct": policy_rate + 0.15},
            {"tenor_months": 18, "rate_pct": policy_rate + 0.20},
            {"tenor_months": 24, "rate_pct": policy_rate + 0.25}
        ]
        
        as_of = date.today()
        
        payload = {
            "as_of": as_of.isoformat(),
            "points": points,
            "source_url": "https://www.snb.ch (approximation)",
            "idempotency_key": f"ois-{as_of.isoformat()}-approx"
        }
        
        print(f"‚ö†Ô∏è  OIS approximatif: {policy_rate}% (taux directeur)")
        return payload
    
    def collect_snb_forecast(self) -> Optional[Dict[str, Any]]:
        """
        Collecte les pr√©visions BNS (trimestriel)
        
        Note: Le parsing de PDF est complexe. Pour l'instant, utilise des valeurs par d√©faut.
        TODO: Impl√©menter parser PDF ou attendre publication structur√©e
        """
        print("\nüè¶ Collecte pr√©visions BNS...")
        
        # V√©rifier si on est dans un mois de MPA (mars, juin, sept, d√©c)
        current_month = date.today().month
        if current_month not in [3, 6, 9, 12]:
            print("‚ÑπÔ∏è  Pas de MPA ce mois-ci (seulement mars, juin, sept, d√©c)")
            return None
        
        # Mode simulation : utiliser derni√®res pr√©visions connues
        print("üß™ Utilisation pr√©visions BNS (MPA 25 septembre 2025)")
        
        current_year = date.today().year
        meeting_date = date.today()
        
        # Pr√©visions officielles BNS (MPA 25 septembre 2025)
        # Source: Communiqu√© BNS du 25.09.2025
        forecast = {
            "2025": 0.2,  # Inflation moyenne 2025: 0.2%
            "2026": 0.5,  # Inflation moyenne 2026: 0.5%
            "2027": 0.7   # Inflation moyenne 2027: 0.7%
        }
        
        payload = {
            "meeting_date": meeting_date.isoformat(),
            "forecast": forecast,
            "source_url": SNB_MPA_URL,
            "pdf_url": f"{SNB_MPA_URL}/mpa-{meeting_date.strftime('%Y-%m')}.pdf",
            "idempotency_key": f"snb-mpa-{meeting_date.isoformat()}-auto"
        }
        
        print(f"‚úÖ Pr√©visions BNS: {forecast}")
        return payload
    
    def ingest_data(self, endpoint: str, data: Dict[str, Any]) -> bool:
        """Envoie les donn√©es vers l'API"""
        try:
            url = f"{API_BASE_URL}/api/snb/ingest/{endpoint}"
            print(f"üì§ Envoi vers {url}")
            
            response = requests.post(url, json=data, timeout=30)
            
            if response.status_code in [200, 201]:
                print("‚úÖ Donn√©es ing√©r√©es")
                self.results.append(f"{endpoint}: OK")
                return True
            elif response.status_code == 409:
                print("‚ÑπÔ∏è  Donn√©es d√©j√† existantes")
                self.results.append(f"{endpoint}: D√©j√† existant")
                return True
            else:
                print(f"‚ùå Erreur {response.status_code}: {response.text}")
                self.errors.append(f"{endpoint}: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur d'envoi: {e}")
            self.errors.append(f"{endpoint}: {str(e)}")
            return False
    
    def run_model(self) -> bool:
        """Lance le calcul du mod√®le"""
        try:
            url = f"{API_BASE_URL}/api/snb/model/run"
            print(f"\nüßÆ Calcul du mod√®le...")
            
            response = requests.post(url, json={}, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print("‚úÖ Mod√®le calcul√©")
                    output = result.get("result", {})
                    print(f"   ‚Üí i* = {output.get('i_star_next_pct', 0):.2f}%")
                    probs = output.get('probs', {})
                    print(f"   ‚Üí Hold = {probs.get('hold', 0):.1%}")
                    self.results.append("Mod√®le: Calcul√©")
                    return True
            
            print(f"‚ùå Erreur calcul")
            self.errors.append("Mod√®le: √âchec calcul")
            return False
            
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
            self.errors.append(f"Mod√®le: {str(e)}")
            return False
    
    def send_notification(self):
        """Envoie une notification par email (optionnel)"""
        if not NOTIFICATION_EMAIL:
            return
        
        # TODO: Impl√©menter envoi email via SMTP ou service
        print(f"üìß Notification envoy√©e √† {NOTIFICATION_EMAIL}")
    
    def run_daily_collection(self):
        """Collecte quotidienne (OIS seulement)"""
        print("üåÖ === COLLECTE QUOTIDIENNE ===")
        
        # OIS depuis Eurex (fallback vers approximation si √©chec)
        ois_data = self.collect_ois_from_eurex()
        if ois_data:
            self.ingest_data("ois", ois_data)
        
        # Relancer le mod√®le
        self.run_model()
    
    def collect_neer(self) -> Optional[Dict[str, Any]]:
        """
        Collecte le NEER depuis l'API officielle SNB
        """
        print("\nüí± Collecte NEER depuis data.snb.ch...")
        
        try:
            from snb_neer_collector import collect_neer_from_snb_api
            neer_data = collect_neer_from_snb_api()
            return neer_data
        except Exception as e:
            print(f"‚ùå Erreur collecte NEER: {e}")
            self.errors.append(f"NEER: {str(e)}")
            return None
    
    def run_monthly_collection(self):
        """Collecte mensuelle (CPI + KOF + NEER)"""
        print("üìÖ === COLLECTE MENSUELLE ===")
        
        # CPI
        cpi_data = self.collect_cpi()
        if cpi_data:
            self.ingest_data("cpi", cpi_data)
        
        # KOF
        kof_data = self.collect_kof()
        if kof_data:
            self.ingest_data("kof", kof_data)
        
        # NEER (nouveau!)
        neer_data = self.collect_neer()
        if neer_data:
            self.ingest_data("neer", neer_data)
        
        # OIS depuis Eurex (fallback vers approximation si √©chec)
        ois_data = self.collect_ois_from_eurex()
        if ois_data:
            self.ingest_data("ois", ois_data)
        
        # Relancer le mod√®le
        self.run_model()
    
    def run_quarterly_collection(self):
        """Collecte trimestrielle (BNS)"""
        print("üìÜ === COLLECTE TRIMESTRIELLE ===")
        
        # Pr√©visions BNS
        snb_data = self.collect_snb_forecast()
        if snb_data:
            self.ingest_data("snb-forecast", snb_data)
        
        # Tout recalculer
        self.run_monthly_collection()
    
    def print_summary(self):
        """Affiche le r√©sum√©"""
        print("\n" + "="*60)
        print("üìä R√âSUM√â DE LA COLLECTE")
        print("="*60)
        
        if self.results:
            print("\n‚úÖ Succ√®s:")
            for r in self.results:
                print(f"   ‚Ä¢ {r}")
        
        if self.errors:
            print("\n‚ùå Erreurs:")
            for e in self.errors:
                print(f"   ‚Ä¢ {e}")
        
        if not self.errors:
            print("\nüéâ Collecte r√©ussie √† 100%")
        else:
            print(f"\n‚ö†Ô∏è  {len(self.errors)} erreur(s)")
        
        print(f"\nüåê Voir r√©sultats: {API_BASE_URL}/snb-taux")
        print("="*60)


def main():
    parser = argparse.ArgumentParser(description="Scraper automatique SNB")
    parser.add_argument("--daily", action="store_true", help="Collecte quotidienne (OIS)")
    parser.add_argument("--monthly", action="store_true", help="Collecte mensuelle (CPI + KOF)")
    parser.add_argument("--quarterly", action="store_true", help="Collecte trimestrielle (BNS)")
    parser.add_argument("--all", action="store_true", help="Tout collecter")
    
    args = parser.parse_args()
    
    if not any(vars(args).values()):
        parser.print_help()
        return
    
    scraper = SNBAutoScraper()
    
    try:
        if args.all or args.quarterly:
            scraper.run_quarterly_collection()
        elif args.monthly:
            scraper.run_monthly_collection()
        elif args.daily:
            scraper.run_daily_collection()
        
        scraper.print_summary()
        scraper.send_notification()
        
        # Exit code selon succ√®s
        sys.exit(0 if not scraper.errors else 1)
        
    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

