
# ========== CHATBOT AM√âLIOR√â V2 - STABLE ET INTELLIGENT ==========

@app.route("/api/chatbot", methods=["POST"])
def chatbot():
    """Chatbot AM√âLIOR√â v2.0 - Stable, rapide et intelligent"""
    try:
        start_time = time.time()
        data = request.get_json()
        if not data:
            return jsonify({"error": "Donn√©es requises"}), 400
        
        query = data.get("message", "").strip()
        if not query:
            return jsonify({"error": "Message requis"}), 400
        
        # NOUVEAU: D√©tection intelligente d'intention
        intent = detect_chat_intent(query)
        
        # D√âSACTIV√â: Celery pour √©viter les timeouts
        # Traitement SYNCHRONE direct pour stabilit√©
        
        # Session et historique
        session_id = data.get("session_id", str(uuid.uuid4()))
        history = data.get("history", [])[-5:]  # Limiter l'historique
        
        # R√©cup√©rer les items avec cache
        items = smart_cache.get('items')
        if items is None:
            items = AdvancedDataManager.fetch_all_items()
            smart_cache.set('items', items, ttl=60)
        
        # Analyse rapide des donn√©es
        analytics = AdvancedDataManager.calculate_advanced_analytics(items)
        
        # AM√âLIORATION 1: R√©ponses rapides pour questions simples
        quick_response = get_quick_response(query, items, analytics)
        if quick_response:
            return jsonify({
                "reply": quick_response,
                "metadata": {
                    "mode": "quick",
                    "response_time": time.time() - start_time,
                    "intent": intent
                }
            })
        
        # AM√âLIORATION 2: Utiliser l'IA am√©lior√©e avec timeout court
        try:
            # Import des nouvelles capacit√©s
            from enhanced_chatbot_manager import EnhancedChatbotManager
            enhanced_bot = EnhancedChatbotManager()
            
            # Analyse d'intention avanc√©e
            intent_analysis = enhanced_bot.analyze_user_intent(query)
            
            # G√©n√©rer suggestions intelligentes
            context = {
                "last_category": get_last_category(items),
                "high_value_items": len([i for i in items if getattr(i, 'current_value', 0) > 100000]) > 0
            }
            suggestions = enhanced_bot.generate_smart_suggestions(context)
            
            # Si demande de pr√©diction
            if intent_analysis['intents'].get('prediction'):
                # Obtenir l'item concern√©
                item_name = extract_item_name(query)
                item = next((i for i in items if item_name.lower() in getattr(i, 'name', '').lower()), None)
                if item:
                    prediction = enhanced_bot.predict_future_value({
                        'name': getattr(item, 'name', ''),
                        'category': getattr(item, 'category', ''),
                        'current_value': getattr(item, 'current_value', 0)
                    })
                    
                    response = format_prediction_response(prediction, item)
                    return jsonify({
                        "reply": response,
                        "suggestions": suggestions,
                        "metadata": {
                            "mode": "prediction",
                            "response_time": time.time() - start_time
                        }
                    })
            
            # Si demande d'export
            if intent_analysis['intents'].get('export'):
                return jsonify({
                    "reply": "üì• Export disponible ! Utilisez les boutons ci-dessous:",
                    "actions": [
                        {"type": "export_pdf", "label": "üìÑ T√©l√©charger PDF"},
                        {"type": "export_excel", "label": "üìä T√©l√©charger Excel"}
                    ],
                    "suggestions": suggestions,
                    "metadata": {"mode": "export"}
                })
            
        except ImportError:
            # Fallback si enhanced_chatbot_manager n'existe pas
            pass
        except Exception as e:
            logger.warning(f"Enhanced chatbot error: {e}")
        
        # AM√âLIORATION 3: Utiliser GPT avec timeout strict
        if ai_engine:
            try:
                # Timeout de 10 secondes max
                with timeout(10):
                    response = generate_smart_response(query, items, analytics, history)
            except TimeoutError:
                response = "‚ö° R√©ponse rapide: J'ai {} objets d'une valeur totale de {:,.0f} CHF dans votre collection.".format(
                    len(items),
                    sum(getattr(i, 'current_value', 0) for i in items)
                )
            
            return jsonify({
                "reply": response,
                "suggestions": get_contextual_suggestions(query, response),
                "metadata": {
                    "items_analyzed": len(items),
                    "mode": "ai_optimized",
                    "response_time": time.time() - start_time,
                    "stable": True
                }
            })
        else:
            # Fallback intelligent sans IA
            return jsonify({
                "reply": generate_fallback_response(query, items, analytics),
                "metadata": {
                    "mode": "fallback",
                    "response_time": time.time() - start_time
                }
            })
    
    except Exception as e:
        logger.error(f"Erreur chatbot: {e}")
        # R√©ponse d'erreur informative
        return jsonify({
            "reply": "üòä Je rencontre un petit souci technique. En attendant, voici un r√©sum√©: Vous avez {} objets dans votre collection.".format(
                len(AdvancedDataManager.fetch_all_items()) if 'items' not in locals() else len(items)
            ),
            "error": str(e),
            "metadata": {"mode": "error_recovery"}
        }), 200  # Retour 200 pour √©viter les erreurs c√¥t√© client


def detect_chat_intent(query: str) -> str:
    """D√©tecte rapidement l'intention de l'utilisateur"""
    query_lower = query.lower()
    
    if any(word in query_lower for word in ['valeur', 'total', 'combien', 'prix']):
        return 'value_analysis'
    elif any(word in query_lower for word in ['ajouter', 'cr√©er', 'nouveau']):
        return 'create_item'
    elif any(word in query_lower for word in ['vendre', 'vente', 'sold']):
        return 'sales_analysis'
    elif any(word in query_lower for word in ['pr√©dire', 'futur', 'sera', '√©volution']):
        return 'prediction'
    elif any(word in query_lower for word in ['export', 'pdf', 'excel', 'rapport']):
        return 'export'
    elif any(word in query_lower for word in ['meilleur', 'top', 'plus']):
        return 'top_items'
    else:
        return 'general'


def get_quick_response(query: str, items: list, analytics: dict) -> str:
    """G√©n√®re des r√©ponses rapides pour les questions simples"""
    query_lower = query.lower()
    
    # Questions sur la valeur totale
    if 'valeur total' in query_lower or 'combien vaut' in query_lower:
        total_value = analytics.get('total_value', 0)
        return f"üí∞ **Valeur totale de votre collection**: {total_value:,.0f} CHF\n\n"                f"üìä R√©partition:\n"                f"‚Ä¢ {analytics.get('available_count', 0)} objets disponibles\n"                f"‚Ä¢ {analytics.get('sold_count', 0)} objets vendus\n"                f"‚Ä¢ {analytics.get('for_sale_count', 0)} objets en vente"
    
    # Questions sur le nombre d'objets
    if 'combien' in query_lower and ('objet' in query_lower or 'item' in query_lower):
        return f"üì¶ Vous avez **{len(items)} objets** dans votre collection:\n\n"                f"‚Ä¢ Disponibles: {analytics.get('available_count', 0)}\n"                f"‚Ä¢ En vente: {analytics.get('for_sale_count', 0)}\n"                f"‚Ä¢ Vendus: {analytics.get('sold_count', 0)}"
    
    # Questions sur les ventes
    if 'vente' in query_lower or 'vendu' in query_lower:
        sold_value = analytics.get('total_sold_value', 0)
        sold_count = analytics.get('sold_count', 0)
        return f"üí∏ **Analyse des ventes**:\n\n"                f"‚Ä¢ Objets vendus: {sold_count}\n"                f"‚Ä¢ Valeur totale des ventes: {sold_value:,.0f} CHF\n"                f"‚Ä¢ Plus-value r√©alis√©e: {analytics.get('realized_gains', 0):,.0f} CHF"
    
    # Questions sur les cat√©gories
    for category in ['voiture', 'montre', 'bateau', 'action', 'immobilier']:
        if category in query_lower:
            cat_items = [i for i in items if category in getattr(i, 'category', '').lower()]
            if cat_items:
                cat_value = sum(getattr(i, 'current_value', 0) for i in cat_items)
                return f"üè∑Ô∏è **{category.capitalize()}s dans votre collection**:\n\n"                        f"‚Ä¢ Nombre: {len(cat_items)}\n"                        f"‚Ä¢ Valeur totale: {cat_value:,.0f} CHF\n"                        f"‚Ä¢ Valeur moyenne: {cat_value/len(cat_items):,.0f} CHF"
    
    return None


def generate_smart_response(query: str, items: list, analytics: dict, history: list) -> str:
    """G√©n√®re une r√©ponse intelligente avec l'IA"""
    # Limiter le contexte pour √©viter les timeouts
    context = {
        "total_items": len(items),
        "total_value": analytics.get('total_value', 0),
        "categories": analytics.get('categories_summary', {}),
        "top_items": analytics.get('top_valued_items', [])[:3]
    }
    
    # Prompt optimis√© pour r√©ponses rapides
    prompt = f"""Tu es l'assistant BONVIN. R√©ponds de mani√®re CONCISE et STRUCTUR√âE.

Question: {query}

Contexte:
- Total objets: {context['total_items']}
- Valeur totale: {context['total_value']:,.0f} CHF
- Cat√©gories: {', '.join(context['categories'].keys()) if context['categories'] else 'N/A'}

R√®gles:
1. Maximum 5 lignes de r√©ponse
2. Utilise des bullets points
3. Inclus des √©mojis pertinents
4. Sois pr√©cis avec les chiffres
5. Termine par une suggestion d'action"""
    
    try:
        if ai_engine and hasattr(ai_engine, 'openai_client'):
            response = ai_engine.openai_client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": "Tu es un assistant de gestion de patrimoine. Sois concis et pr√©cis."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.7,
                timeout=10
            )
            return response.choices[0].message.content
    except Exception as e:
        logger.error(f"AI response error: {e}")
    
    return generate_fallback_response(query, items, analytics)


def generate_fallback_response(query: str, items: list, analytics: dict) -> str:
    """G√©n√®re une r√©ponse de fallback intelligente sans IA"""
    total_value = analytics.get('total_value', 0)
    total_items = len(items)
    
    response = f"üìä **R√©sum√© de votre collection**\n\n"
    response += f"‚Ä¢ **{total_items} objets** au total\n"
    response += f"‚Ä¢ **Valeur totale**: {total_value:,.0f} CHF\n"
    
    # Ajouter les top cat√©gories
    categories = analytics.get('categories_summary', {})
    if categories:
        top_cats = sorted(categories.items(), key=lambda x: x[1].get('total_value', 0), reverse=True)[:3]
        response += f"\n**Top cat√©gories**:\n"
        for cat, data in top_cats:
            response += f"‚Ä¢ {cat}: {data.get('count', 0)} objets ({data.get('total_value', 0):,.0f} CHF)\n"
    
    response += f"\nüí° *Posez-moi une question sp√©cifique pour plus de d√©tails !*"
    
    return response


def get_contextual_suggestions(query: str, response: str) -> list:
    """G√©n√®re des suggestions contextuelles"""
    suggestions = []
    
    if 'valeur' in query.lower():
        suggestions.extend([
            "√âvolution sur 6 mois",
            "Top 5 des plus values",
            "R√©partition par cat√©gorie"
        ])
    elif 'vente' in query.lower():
        suggestions.extend([
            "Objets √† fort potentiel",
            "Analyse des plus-values",
            "Strat√©gie de vente optimale"
        ])
    else:
        suggestions.extend([
            "Valeur totale du portefeuille",
            "Objets les plus pr√©cieux",
            "Performance des investissements"
        ])
    
    return suggestions[:3]


def format_prediction_response(prediction: dict, item) -> str:
    """Formate une r√©ponse de pr√©diction"""
    response = f"üîÆ **Pr√©diction pour {getattr(item, 'name', 'cet objet')}**\n\n"
    response += f"Valeur actuelle: {getattr(item, 'current_value', 0):,.0f} CHF\n\n"
    response += "**Sc√©narios √† 12 mois:**\n"
    response += f"‚Ä¢ üìâ Pessimiste: {prediction['pessimistic']:,.0f} CHF\n"
    response += f"‚Ä¢ üìä R√©aliste: {prediction['realistic']:,.0f} CHF\n"
    response += f"‚Ä¢ üìà Optimiste: {prediction['optimistic']:,.0f} CHF\n\n"
    response += f"Confiance: {prediction['confidence']:.0%}"
    
    return response


def extract_item_name(query: str) -> str:
    """Extrait le nom de l'objet de la requ√™te"""
    # Logique simple d'extraction
    words = query.lower().split()
    # Chercher apr√®s "de", "mon", "ma", etc.
    for i, word in enumerate(words):
        if word in ['de', 'mon', 'ma', 'mes', 'le', 'la', 'les']:
            if i + 1 < len(words):
                return ' '.join(words[i+1:])
    return query


def get_last_category(items: list) -> str:
    """Obtient la derni√®re cat√©gorie utilis√©e"""
    if items:
        # Trier par date de modification si disponible
        sorted_items = sorted(items, key=lambda x: getattr(x, 'updated_at', ''), reverse=True)
        if sorted_items:
            return getattr(sorted_items[0], 'category', '')
    return ''


# Fonction de timeout pour √©viter les blocages
from contextlib import contextmanager
import signal

@contextmanager
def timeout(seconds):
    def timeout_handler(signum, frame):
        raise TimeoutError()
    
    # Setup
    old_handler = signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(seconds)
    
    try:
        yield
    finally:
        # Cleanup
        signal.alarm(0)
        signal.signal(signal.SIGALRM, old_handler)
