#!/usr/bin/env python3
"""
Utilitaires pour l'API Responses de GPT-5
Fonctions d'extraction de texte et de gestion des r√©ponses
"""

import json
import logging
from typing import Optional, Dict, Any, List
from openai import OpenAI

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def extract_text(res) -> str:
    """
    Extraction robuste du texte de la r√©ponse GPT-5
    
    Args:
        res: Objet r√©ponse de l'API Responses
        
    Returns:
        str: Texte extrait ou cha√Æne vide
    """
    try:
        # 1) Voie rapide - output_text direct
        if getattr(res, "output_text", None):
            t = (res.output_text or "").strip()
            if t:
                logger.debug("‚úÖ Texte extrait via output_text direct")
                return t
        
        # 2) Parcourir la structure "output"
        chunks = []
        for item in getattr(res, "output", []):
            # Messages assistant
            if getattr(item, "role", "") == "assistant":
                for part in getattr(item, "content", []):
                    if getattr(part, "type", "") == "output_text" and getattr(part, "text", None):
                        chunks.append(part.text)
        
        if chunks:
            result = "\n".join(chunks).strip()
            logger.debug("‚úÖ Texte extrait via structure output")
            return result
        
        # 3) Fallback - essayer d'autres attributs
        fallback_attrs = ["text", "content", "response", "message"]
        for attr in fallback_attrs:
            if hasattr(res, attr) and getattr(res, attr):
                value = getattr(res, attr)
                if isinstance(value, str) and value.strip():
                    logger.debug(f"‚úÖ Texte extrait via fallback {attr}")
                    return value.strip()
        
        logger.warning("‚ö†Ô∏è Aucun texte trouv√© dans la r√©ponse")
        return ""
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'extraction du texte: {e}")
        return ""

def extract_metadata(res) -> Dict[str, Any]:
    """
    Extraction des m√©tadonn√©es utiles de la r√©ponse
    
    Args:
        res: Objet r√©ponse de l'API Responses
        
    Returns:
        Dict: M√©tadonn√©es extraites
    """
    metadata = {}
    
    try:
        # Request ID
        metadata["request_id"] = getattr(res, "_request_id", None)
        
        # Usage et tokens
        if hasattr(res, "usage") and res.usage:
            usage = res.usage
            metadata["usage"] = {
                "input_tokens": getattr(usage, "input_tokens", None),
                "output_tokens": getattr(usage, "output_tokens", None),
                "total_tokens": getattr(usage, "total_tokens", None)
            }
            
            # D√©tails des tokens de sortie (si disponibles)
            if hasattr(usage, "output_tokens_details"):
                output_details = usage.output_tokens_details
                metadata["output_tokens_details"] = {
                    "reasoning_tokens": getattr(output_details, "reasoning_tokens", None),
                    "text_tokens": getattr(output_details, "text_tokens", None)
                }
        
        # Status
        metadata["status"] = getattr(res, "status", None)
        
        # Raisonnement (si activ√©)
        if hasattr(res, "reasoning") and res.reasoning:
            metadata["reasoning"] = {
                "items_count": len(res.reasoning),
                "types": [getattr(item, "type", "unknown") for item in res.reasoning]
            }
        
        # Output structur√© (si disponible)
        if hasattr(res, "output") and res.output:
            metadata["output"] = {
                "items_count": len(res.output),
                "types": [getattr(item, "type", "unknown") for item in res.output]
            }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'extraction des m√©tadonn√©es: {e}")
    
    return metadata

def analyze_response_quality(res) -> Dict[str, Any]:
    """
    Analyse de la qualit√© de la r√©ponse
    
    Args:
        res: Objet r√©ponse de l'API Responses
        
    Returns:
        Dict: Analyse de la qualit√©
    """
    analysis = {
        "has_text": False,
        "text_length": 0,
        "reasoning_used": False,
        "potential_issues": []
    }
    
    try:
        # Extraire le texte
        text = extract_text(res)
        analysis["has_text"] = bool(text)
        analysis["text_length"] = len(text)
        
        # V√©rifier le raisonnement
        metadata = extract_metadata(res)
        if metadata.get("output_tokens_details", {}).get("reasoning_tokens"):
            analysis["reasoning_used"] = True
            reasoning_tokens = metadata["output_tokens_details"]["reasoning_tokens"]
            
            # D√©tecter les "drains" de raisonnement
            if reasoning_tokens > 0 and not text.strip():
                analysis["potential_issues"].append(
                    "DRAIN_DE_RAISONNEMENT: Le mod√®le a consomm√© des tokens de raisonnement sans √©mettre de texte"
                )
        
        # V√©rifier la longueur du texte
        if text and len(text) < 10:
            analysis["potential_issues"].append("TEXTE_TROP_COURT: La r√©ponse semble incompl√®te")
        
        # V√©rifier le statut
        if metadata.get("status") != "completed":
            analysis["potential_issues"].append(f"STATUS_INCOMPLET: {metadata.get('status')}")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'analyse de la qualit√©: {e}")
        analysis["potential_issues"].append(f"ERREUR_ANALYSE: {e}")
    
    return analysis

def create_responses_client(api_key: Optional[str] = None) -> OpenAI:
    """
    Cr√©ation d'un client OpenAI configur√© pour l'API Responses
    
    Args:
        api_key: Cl√© API OpenAI (optionnelle, utilise OPENAI_API_KEY par d√©faut)
        
    Returns:
        OpenAI: Client configur√©
    """
    if not api_key:
        import os
        api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("Cl√© API OpenAI requise")
    
    return OpenAI(api_key=api_key)

def create_optimized_prompt(base_instructions: str, force_output: bool = True) -> str:
    """
    Cr√©ation d'un prompt optimis√© pour √©viter les drains de raisonnement
    
    Args:
        base_instructions: Instructions de base
        force_output: Forcer la sortie de texte
        
    Returns:
        str: Prompt optimis√©
    """
    if force_output:
        output_instructions = """
IMPORTANT: Tu DOIS √©mettre une r√©ponse finale en texte.
- Commence ta r√©ponse par "OK ‚Äì"
- Sois concis et direct
- √âvite de rester dans le raisonnement interne
"""
        return f"{base_instructions}\n\n{output_instructions}"
    
    return base_instructions

def parse_json_response(text: str) -> Optional[Dict[str, Any]]:
    """
    Parsing s√©curis√© d'une r√©ponse JSON
    
    Args:
        text: Texte de la r√©ponse
        
    Returns:
        Dict ou None si parsing √©choue
    """
    try:
        # Nettoyer le texte
        cleaned_text = text.strip()
        
        # Essayer de trouver du JSON dans le texte
        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3]
        
        cleaned_text = cleaned_text.strip()
        
        # Parser le JSON
        return json.loads(cleaned_text)
        
    except json.JSONDecodeError as e:
        logger.warning(f"‚ö†Ô∏è √âchec du parsing JSON: {e}")
        return None
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du parsing JSON: {e}")
        return None

def stream_response_text(client: OpenAI, **kwargs) -> str:
    """
    Streaming de la r√©ponse avec accumulation du texte
    
    Args:
        client: Client OpenAI
        **kwargs: Param√®tres pour client.responses.stream
        
    Returns:
        str: Texte complet de la r√©ponse
    """
    try:
        with client.responses.stream(**kwargs) as stream:
            buffer = []
            
            for event in stream:
                if event.type == "response.output_text.delta":
                    delta = getattr(event, 'delta', '')
                    buffer.append(delta)
                elif event.type == "response.completed":
                    break
            
            return "".join(buffer).strip()
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du streaming: {e}")
        return ""

# Fonction de compatibilit√© pour l'ancien code
def extract_output_text(res) -> str:
    """
    Alias pour extract_text (compatibilit√©)
    """
    return extract_text(res)

# Exemple d'utilisation
if __name__ == "__main__":
    print("üõ†Ô∏è Module utilitaire GPT-5 Responses")
    print("Fonctions disponibles:")
    print("  - extract_text(res): Extraction robuste du texte")
    print("  - extract_metadata(res): Extraction des m√©tadonn√©es")
    print("  - analyze_response_quality(res): Analyse de la qualit√©")
    print("  - create_optimized_prompt(): Cr√©ation de prompts optimis√©s")
    print("  - parse_json_response(text): Parsing JSON s√©curis√©")
    print("  - stream_response_text(): Streaming avec accumulation")
