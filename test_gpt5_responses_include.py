#!/usr/bin/env python3
"""
Test complet de l'API Responses de GPT-5 avec tous les paramÃ¨tres include
Teste les diffÃ©rentes options d'enrichissement des rÃ©ponses
"""

import os
import sys
import json
from datetime import datetime
from openai import OpenAI

def check_environment():
    """VÃ©rifie la configuration de l'environnement"""
    print("ğŸ” VÃ‰RIFICATION DE L'ENVIRONNEMENT")
    print("=" * 50)
    
    # VÃ©rifier OpenAI API Key
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key:
        print("âŒ OPENAI_API_KEY non configurÃ©e")
        print("ğŸ’¡ Pour configurer :")
        print("   1. CrÃ©ez un fichier .env avec OPENAI_API_KEY=votre_clÃ©")
        print("   2. Ou exportez la variable : set OPENAI_API_KEY=votre_clÃ©")
        return False
    
    print(f"âœ… OPENAI_API_KEY configurÃ©e: {openai_key[:10]}...")
    
    # VÃ©rifier la version d'OpenAI
    try:
        import openai
        print(f"âœ… Version OpenAI: {openai.__version__}")
    except Exception as e:
        print(f"âš ï¸ Impossible de vÃ©rifier la version OpenAI: {e}")
    
    return True

def test_basic_responses(client):
    """Test de base sans paramÃ¨tres include"""
    print("\nğŸ¯ TEST 1: RÃ‰PONSE DE BASE (SANS INCLUDE)")
    print("-" * 50)
    
    try:
        response = client.responses.create(
            model="gpt-5",
            instructions="Tu es un analyste financier. Analyse briÃ¨vement le marchÃ© actuel en 2-3 phrases. Commence par 'ANALYSE:'",
            input="Quelle est la situation actuelle du marchÃ© boursier ?",
            max_output_tokens=150
        )
        
        print(f"âœ… SuccÃ¨s - Status: {getattr(response, 'status', 'N/A')}")
        print(f"ğŸ“ Output text: '{getattr(response, 'output_text', 'N/A')}'")
        
        # Afficher les mÃ©tadonnÃ©es
        print(f"\nğŸ“Š MÃ‰TADONNÃ‰ES:")
        print(f"  - Request ID: {getattr(response, '_request_id', 'N/A')}")
        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            print(f"  - Input tokens: {getattr(usage, 'input_tokens', 'N/A')}")
            print(f"  - Output tokens: {getattr(usage, 'output_tokens', 'N/A')}")
            print(f"  - Total tokens: {getattr(usage, 'total_tokens', 'N/A')}")
        
        return response
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None

def test_with_reasoning(client):
    """Test avec le paramÃ¨tre reasoning"""
    print("\nğŸ§  TEST 2: AVEC RAISONNEMENT (REASONING)")
    print("-" * 50)
    
    try:
        response = client.responses.create(
            model="gpt-5",
            instructions="Tu es un analyste financier. Analyse le marchÃ© en dÃ©tail. Commence par 'ANALYSE:'",
            input="Quelle est la situation actuelle du marchÃ© boursier ?",
            max_output_tokens=200,
            reasoning=True
        )
        
        print(f"âœ… SuccÃ¨s - Status: {getattr(response, 'status', 'N/A')}")
        print(f"ğŸ“ Output text: '{getattr(response, 'output_text', 'N/A')}'")
        
        # VÃ©rifier le raisonnement
        if hasattr(response, 'reasoning') and response.reasoning:
            print(f"\nğŸ§  RAISONNEMENT:")
            for i, item in enumerate(response.reasoning):
                print(f"  Item {i}:")
                print(f"    - Type: {getattr(item, 'type', 'N/A')}")
                print(f"    - Status: {getattr(item, 'status', 'N/A')}")
                if hasattr(item, 'content') and item.content:
                    print(f"    - Content: {len(item.content)} Ã©lÃ©ments")
        
        return response
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None

def test_with_include_parameters(client):
    """Test avec diffÃ©rents paramÃ¨tres include"""
    print("\nğŸ”§ TEST 3: PARAMÃˆTRES INCLUDE")
    print("-" * 50)
    
    # Liste des paramÃ¨tres include Ã  tester
    include_options = [
        ["reasoning.encrypted_content"],
        ["message.output_text.logprobs"],
        ["reasoning.encrypted_content", "message.output_text.logprobs"]
    ]
    
    for i, include_list in enumerate(include_options):
        print(f"\nğŸ“‹ Test {i+1}: {include_list}")
        print("-" * 30)
        
        try:
            response = client.responses.create(
                model="gpt-5",
                instructions="Tu es un analyste financier. Donne une analyse concise. Commence par 'ANALYSE:'",
                input="Quelle est la situation actuelle du marchÃ© boursier ?",
                max_output_tokens=150,
                include=include_list
            )
            
            print(f"âœ… SuccÃ¨s - Status: {getattr(response, 'status', 'N/A')}")
            print(f"ğŸ“ Output text: '{getattr(response, 'output_text', 'N/A')}'")
            
            # VÃ©rifier les Ã©lÃ©ments inclus
            if "reasoning.encrypted_content" in include_list:
                if hasattr(response, 'reasoning') and response.reasoning:
                    print(f"  ğŸ§  Reasoning items: {len(response.reasoning)}")
                    for item in response.reasoning:
                        if hasattr(item, 'encrypted_content'):
                            print(f"    - Encrypted content: {getattr(item, 'encrypted_content', 'N/A')}")
            
            if "message.output_text.logprobs" in include_list:
                if hasattr(response, 'output') and response.output:
                    for item in response.output:
                        if hasattr(item, 'logprobs'):
                            print(f"  ğŸ“Š Logprobs disponibles: {getattr(item, 'logprobs', 'N/A')}")
            
        except Exception as e:
            print(f"âŒ Erreur: {e}")

def test_streaming_responses(client):
    """Test du streaming avec l'API Responses"""
    print("\nğŸŒŠ TEST 4: STREAMING RESPONSES")
    print("-" * 50)
    
    try:
        with client.responses.stream(
            model="gpt-5",
            instructions="Tu es un analyste financier. Donne une analyse en temps rÃ©el. Commence par 'ANALYSE:'",
            input="Quelle est la situation actuelle du marchÃ© boursier ?",
            max_output_tokens=200,
            text={"type": "text"}
        ) as stream:
            
            print("ğŸ”„ Streaming en cours...")
            buffer = []
            
            for event in stream:
                if event.type == "response.output_text.delta":
                    delta = getattr(event, 'delta', '')
                    buffer.append(delta)
                    print(f"ğŸ“ Delta: '{delta}'")
                elif event.type == "response.completed":
                    print("âœ… Streaming terminÃ©")
                    break
                else:
                    print(f"ğŸ“¡ Event: {event.type}")
            
            final_text = "".join(buffer).strip()
            print(f"\nğŸ“‹ Texte final: '{final_text}'")
            
    except Exception as e:
        print(f"âŒ Erreur streaming: {e}")

def test_extract_text_utility():
    """Test de la fonction utilitaire d'extraction de texte"""
    print("\nğŸ› ï¸ TEST 5: FONCTION UTILITAIRE EXTRACT_TEXT")
    print("-" * 50)
    
    # Simuler une rÃ©ponse pour tester la fonction
    class MockResponse:
        def __init__(self, output_text=None, output=None, usage=None):
            self.output_text = output_text
            self.output = output
            self.usage = usage
            self._request_id = "test_123"
    
    def extract_text(res) -> str:
        """Fonction utilitaire d'extraction de texte"""
        # 1) Voie rapide
        if getattr(res, "output_text", None):
            t = (res.output_text or "").strip()
            if t:
                return t
        
        # 2) Parcourir la structure "output"
        chunks = []
        for item in getattr(res, "output", []):
            # Messages assistant
            if getattr(item, "role", "") == "assistant":
                for part in getattr(item, "content", []):
                    if getattr(part, "type", "") == "output_text" and getattr(part, "text", None):
                        chunks.append(part.text)
        return "\n".join(chunks).strip()
    
    # Test avec output_text
    mock_res1 = MockResponse(output_text="Test de rÃ©ponse")
    result1 = extract_text(mock_res1)
    print(f"âœ… Test output_text: '{result1}'")
    
    # Test avec output structurÃ©
    mock_res2 = MockResponse(
        output=[
            type('MockItem', (), {
                'role': 'assistant',
                'content': [
                    type('MockPart', (), {
                        'type': 'output_text',
                        'text': 'RÃ©ponse structurÃ©e'
                    })()
                ]
            })()
        ]
    )
    result2 = extract_text(mock_res2)
    print(f"âœ… Test output structurÃ©: '{result2}'")
    
    # Test avec rÃ©ponse vide
    mock_res3 = MockResponse()
    result3 = extract_text(mock_res3)
    print(f"âœ… Test rÃ©ponse vide: '{result3}'")

def main():
    """Fonction principale de test"""
    print("ğŸš€ TEST COMPLET DE L'API RESPONSES GPT-5")
    print("=" * 60)
    print(f"â° DÃ©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # VÃ©rifier l'environnement
    if not check_environment():
        return
    
    # Initialiser le client OpenAI
    try:
        client = OpenAI()
        print("âœ… Client OpenAI initialisÃ©")
    except Exception as e:
        print(f"âŒ Erreur initialisation client OpenAI: {e}")
        return
    
    # Tests
    test_basic_responses(client)
    test_with_reasoning(client)
    test_with_include_parameters(client)
    test_streaming_responses(client)
    test_extract_text_utility()
    
    print(f"\nğŸ‰ TESTS TERMINÃ‰S - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()
