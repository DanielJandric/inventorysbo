# gpt5_responses_mvp.py
import os, json, sys
from openai import OpenAI, OpenAIError

MODEL_PRIMARY = os.getenv("MODEL_PRIMARY", "gpt-5")                # alias stable d'abord
MODEL_SECOND  = os.getenv("MODEL_SECOND",  "gpt-5-2025-08-07")     # snapshot si besoin
MAX_OUT       = int(os.getenv("MAX_OUT", "384"))
TIMEOUT_S     = int(os.getenv("TIMEOUT_S", "60"))
FALLBACK_CHAT = os.getenv("FALLBACK_CHAT", "0") == "1"             # fallback chat optionnel

client = OpenAI()

INSTRUCTIONS = (
    "Tu es un analyste march√©s. Texte brut, lisible, concis et actionnable. "
    "Reconnais tendances/corr√©lations/r√©gimes de volatilit√© et commente risques/opportunit√©s. "
    "N'invente aucun chiffre. Autoris√©: **gras** et emojis sobres (‚Üë, ‚Üì, üü¢, üî¥, ‚ö†Ô∏è, üí°). "
    "Structure 3‚Äì5 lignes num√©rot√©es, puis une conclusion. Pas de titres, pas de tableaux, pas de code."
)

def call_responses(prompt_text: str, model: str) -> tuple[str, dict]:
    """Retourne (texte, meta) ‚Äî meta inclut request_id et usage."""
    res = client.responses.create(
        model=model,
        instructions=INSTRUCTIONS,
        input=(
            prompt_text.strip()
            + "\n\n√âcris la R√âPONSE FINALE maintenant en texte brut, 3‚Äì5 lignes num√©rot√©es, puis une conclusion. "
              "Commence par: OK ‚Äì"
        ),
        tool_choice="none",
        text={"format": {"type": "text"}, "verbosity": "medium"},
        max_output_tokens=MAX_OUT,
        timeout=TIMEOUT_S
        # ‚ö†Ô∏è ne PAS envoyer 'reasoning' -> √©vite d'absorber le budget en pens√©e
    )
    out = (res.output_text or "").strip()
    meta = {
        "request_id": getattr(res, "_request_id", None),
        "usage": getattr(res, "usage", None),
        "status": getattr(res, "status", None),
        "model": model,
    }
    return out, meta

def call_chat_fallback(prompt_text: str) -> str:
    """Fallback via Chat Completions (optionnel) pour garantir une sortie."""
    msgs = [
        {"role":"system","content":INSTRUCTIONS},
        {"role":"user","content":(
            prompt_text.strip()
            + "\n\nR√©ponds en texte brut uniquement. Commence par: OK ‚Äì"
        )}
    ]
    resp = client.chat.completions.create(
        model="gpt-5-chat-latest",
        messages=msgs,
        max_tokens=min(MAX_OUT, 600),
        temperature=0.2
    )
    return (resp.choices[0].message.content or "").strip()

def run(prompt: str) -> int:
    # Tentative 1: alias stable
    text, meta = call_responses(prompt, MODEL_PRIMARY)
    print(f"[responses:{MODEL_PRIMARY}] request_id={meta['request_id']} usage={meta['usage']}")
    if text:
        print(text)
        return 0

    # Tentative 2: snapshot
    text, meta = call_responses(prompt, MODEL_SECOND)
    print(f"[responses:{MODEL_SECOND}] request_id={meta['request_id']} usage={meta['usage']}")
    if text:
        print(text)
        return 0

    # Fallback optionnel (d√©sactiv√© par d√©faut)
    if FALLBACK_CHAT:
        print("[info] Responses vide -> fallback chat.gpt-5-chat-latest")
        text = call_chat_fallback(prompt)
        if text:
            print(text)
            return 0

    # Message UX s√ªr si tout √©choue
    print("OK ‚Äì Besoin de pr√©cisions : la sortie est vide avec Responses. Reformule la question en une phrase claire.")
    return 2

if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("Veuillez d√©finir OPENAI_API_KEY.", file=sys.stderr)
        sys.exit(1)
    user_q = sys.argv[1] if len(sys.argv) > 1 else "Quelles opportunit√©s sur l'immobilier cot√© aujourd'hui ?"
    try:
        sys.exit(run(user_q))
    except OpenAIError as e:
        print(f"[OpenAIError] {type(e).__name__}: {e}", file=sys.stderr)
        sys.exit(3)
