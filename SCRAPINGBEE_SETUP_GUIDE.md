# ğŸ Guide de Configuration ScrapingBee

## Vue d'ensemble

ScrapingBee est un service de web scraping professionnel qui offre plusieurs avantages par rapport Ã  Playwright :

### âœ… Avantages de ScrapingBee

1. **Pas de gestion de navigateur** - Plus simple Ã  dÃ©ployer
2. **Anti-dÃ©tection intÃ©grÃ©e** - Ã‰vite les blocages automatiquement
3. **API REST simple** - Plus fiable que Playwright
4. **Gestion des proxies** - Rotation automatique
5. **Moins de ressources** - Pas besoin de navigateur complet
6. **Plan gratuit** - 1000 requÃªtes/mois

### ğŸ”„ Comparaison avec Playwright

| FonctionnalitÃ© | Playwright | ScrapingBee |
|----------------|------------|-------------|
| ComplexitÃ© | Ã‰levÃ©e | Faible |
| Ressources | Ã‰levÃ©es | Faibles |
| Anti-dÃ©tection | Manuel | Automatique |
| DÃ©ploiement | Complexe | Simple |
| CoÃ»t | Gratuit | Payant aprÃ¨s quota |

## ğŸš€ Installation et Configuration

### Ã‰tape 1: Obtenir une clÃ© API ScrapingBee

1. Allez sur [https://www.scrapingbee.com/](https://www.scrapingbee.com/)
2. CrÃ©ez un compte gratuit
3. Obtenez votre clÃ© API dans le dashboard
4. Notez votre clÃ© API

### Ã‰tape 2: Configuration automatique

```bash
python configure_scrapingbee.py
```

### Ã‰tape 3: Configuration manuelle

Ajoutez votre clÃ© API dans le fichier `.env` :

```env
SCRAPINGBEE_API_KEY=votre_cle_api_ici
```

## ğŸ§ª Test de la Configuration

### Test automatique

```bash
python test_scrapingbee_scraper.py
```

### Test manuel

```python
from scrapingbee_scraper import get_scrapingbee_scraper
import asyncio

async def test():
    scraper = get_scrapingbee_scraper()
    scraper.initialize_sync()
    
    task_id = await scraper.create_scraping_task("Tesla stock price", 3)
    result = await scraper.execute_scraping_task(task_id)
    
    print(result)

asyncio.run(test())
```

## ğŸŒ Interface Web

### AccÃ¨s Ã  l'interface

```
http://localhost:5000/scrapingbee-scraper
```

### FonctionnalitÃ©s de l'interface

- âœ… Statut du scraper en temps rÃ©el
- âœ… Configuration des paramÃ¨tres de recherche
- âœ… Actions rapides pour les actions populaires
- âœ… Affichage des rÃ©sultats structurÃ©s
- âœ… MÃ©triques de performance

## ğŸ“¡ API Endpoints

### Statut gÃ©nÃ©ral

```http
GET /api/scrapingbee/status
```

### CrÃ©er et exÃ©cuter une tÃ¢che

```http
POST /api/scrapingbee/scrape
Content-Type: application/json

{
    "prompt": "Tesla stock price today",
    "num_results": 5
}
```

### Statut d'une tÃ¢che

```http
GET /api/scrapingbee/status/{task_id}
```

### ExÃ©cuter une tÃ¢che

```http
POST /api/scrapingbee/execute/{task_id}
```

## ğŸ”§ Configuration AvancÃ©e

### ParamÃ¨tres ScrapingBee

Le scraper utilise les paramÃ¨tres suivants par dÃ©faut :

```python
params = {
    'api_key': self.api_key,
    'url': url,
    'render_js': 'true',  # Rendu JavaScript
    'premium_proxy': 'true',  # Proxy premium
    'country_code': 'us',  # Proxy US
    'extract_rules': json.dumps({
        'title': {'selector': 'title', 'type': 'text'},
        'content': {'selector': 'body', 'type': 'text'}
    })
}
```

### Personnalisation

Vous pouvez modifier ces paramÃ¨tres dans `scrapingbee_scraper.py` :

```python
# Dans la mÃ©thode _scrape_page
params = {
    'api_key': self.api_key,
    'url': url,
    'render_js': 'true',
    'premium_proxy': 'true',
    'country_code': 'us',  # Changer le pays
    'custom_google': 'true',  # Utiliser Google personnalisÃ©
    'extract_rules': json.dumps({
        # Personnaliser les rÃ¨gles d'extraction
    })
}
```

## ğŸ“Š Utilisation dans l'Application

### IntÃ©gration avec Flask

Le ScrapingBee scraper est intÃ©grÃ© dans l'application Flask :

```python
# Initialisation
scrapingbee_scraper_manager = get_scrapingbee_scraper()
scrapingbee_scraper_manager.initialize_sync()

# Utilisation
task_id = await scrapingbee_scraper_manager.create_scraping_task(prompt, num_results)
result = await scrapingbee_scraper_manager.execute_scraping_task(task_id)
```

### Remplacement de Playwright

Pour utiliser ScrapingBee au lieu de Playwright :

```python
# Au lieu de
from intelligent_scraper import IntelligentScraper

# Utilisez
from scrapingbee_scraper import ScrapingBeeScraper
```

## ğŸš¨ DÃ©pannage

### Erreurs courantes

1. **"SCRAPINGBEE_API_KEY requis"**
   - VÃ©rifiez que la clÃ© API est dans le fichier `.env`
   - Relancez l'application aprÃ¨s modification

2. **"API key not valid"**
   - VÃ©rifiez votre clÃ© API sur le dashboard ScrapingBee
   - Assurez-vous que votre compte est actif

3. **"Quota exceeded"**
   - VÃ©rifiez votre quota sur le dashboard ScrapingBee
   - ConsidÃ©rez un plan payant pour plus de requÃªtes

4. **"No results found"**
   - VÃ©rifiez votre connexion internet
   - Essayez avec un prompt diffÃ©rent
   - VÃ©rifiez que le site cible n'est pas bloquÃ©

### Logs de dÃ©bogage

Activez les logs dÃ©taillÃ©s :

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ’° CoÃ»ts et Quotas

### Plan gratuit
- 1000 requÃªtes/mois
- Proxy premium inclus
- Support communautaire

### Plans payants
- Starter: $49/mois - 50,000 requÃªtes
- Business: $199/mois - 250,000 requÃªtes
- Enterprise: Sur mesure

## ğŸ”— Ressources

- [Site web ScrapingBee](https://www.scrapingbee.com/)
- [Documentation API](https://www.scrapingbee.com/docs/)
- [Dashboard](https://app.scrapingbee.com/)
- [Support](https://www.scrapingbee.com/support/)

## ğŸ“ Notes importantes

1. **Respectez les robots.txt** - ScrapingBee respecte automatiquement les robots.txt
2. **Rate limiting** - Le service gÃ¨re automatiquement les limites de taux
3. **DonnÃ©es personnelles** - ScrapingBee ne collecte pas de donnÃ©es personnelles
4. **ConformitÃ©** - VÃ©rifiez la conformitÃ© avec les sites que vous scrapez

## ğŸ¯ Prochaines Ã©tapes

1. Configurez votre clÃ© API ScrapingBee
2. Testez l'interface web
3. IntÃ©grez dans vos workflows existants
4. Surveillez votre utilisation et coÃ»ts
5. Optimisez vos requÃªtes pour rÃ©duire les coÃ»ts 